"use strict";(self.webpackChunk=self.webpackChunk||[]).push([["41305"],{69571:function(e,t,n){n.r(t),n.d(t,{default:()=>u,frontMatter:()=>c,metadata:()=>i,assets:()=>l,toc:()=>d,contentTitle:()=>a});var i=JSON.parse('{"id":"experiments/experiments-system-infomation-v2","title":"System Infomation V2","description":"Improved autoscaling through cgroup aware metric collection.","source":"@site/../docs/experiments/systemInfoV2.mdx","sourceDirName":"experiments","slug":"/experiments/experiments-system-infomation-v2","permalink":"/docs/next/experiments/experiments-system-infomation-v2","draft":false,"unlisted":false,"editUrl":"https://github.com/apify/crawlee/edit/master/website/../docs/experiments/systemInfoV2.mdx","tags":[],"version":"current","lastUpdatedBy":"NathanSavageKaimai","lastUpdatedAt":1741015387000,"frontMatter":{"id":"experiments-system-infomation-v2","title":"System Infomation V2","description":"Improved autoscaling through cgroup aware metric collection."},"sidebar":"docs","previous":{"title":"Request Locking","permalink":"/docs/next/experiments/experiments-request-locking"},"next":{"title":"Upgrading","permalink":"/docs/next/upgrading"}}'),r=n("85893"),s=n("50065"),o=n("47927");let c={id:"experiments-system-infomation-v2",title:"System Infomation V2",description:"Improved autoscaling through cgroup aware metric collection."},a=void 0,l={},d=[{value:"How to enable the experiment",id:"how-to-enable-the-experiment",level:2},{value:"Other changes",id:"other-changes",level:2},{value:"Cgroup detection",id:"cgroup-detection",level:3},{value:"CPU metric collection",id:"cpu-metric-collection",level:3},{value:"Memory metric collection",id:"memory-metric-collection",level:3}];function p(e){let t={a:"a",admonition:"admonition",code:"code",h2:"h2",h3:"h3",p:"p",pre:"pre",...(0,s.a)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsxs)(t.admonition,{type:"caution",children:[(0,r.jsx)(t.p,{children:"This is an experimental feature. While we welcome testers, keep in mind that it is currently not recommended to use this in production."}),(0,r.jsx)(t.p,{children:"The API is subject to change, and we might introduce breaking changes in the future."}),(0,r.jsxs)(t.p,{children:["Should you be using this, feel free to open issues on our ",(0,r.jsx)(t.a,{href:"https://github.com/apify/crawlee",target:"_blank",rel:"noopener",children:"GitHub repository"}),", and we'll take a look."]})]}),"\n",(0,r.jsxs)(t.p,{children:["Starting with the newest ",(0,r.jsx)(t.code,{children:"crawlee"})," beta, we have introduced a new crawler option that enables an improved metric collection system.\nThis new system should collect cpu and memory metrics more accurately in containerised environments by checking for cgroup enforce limits."]}),"\n",(0,r.jsx)(t.h2,{id:"how-to-enable-the-experiment",children:"How to enable the experiment"}),"\n",(0,r.jsx)(t.admonition,{type:"note",children:(0,r.jsxs)(t.p,{children:["This example shows how to enable the experiment in the ",(0,r.jsx)(o.Z,{to:"cheerio-crawler/class/CheerioCrawler",children:(0,r.jsx)(t.code,{children:"CheerioCrawler"})}),",\nbut you can apply this to any crawler type."]})}),"\n",(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-ts",children:"import { CheerioCrawler, Configuration } from 'crawlee';\n\nConfiguration.set('systemInfoV2', true);\n\nconst crawler = new CheerioCrawler({\n    async requestHandler({ $, request }) {\n        const title = $('title').text();\n        console.log(`The title of \"${request.url}\" is: ${title}.`);\n    },\n});\n\nawait crawler.run(['https://crawlee.dev']);\n"})}),"\n",(0,r.jsx)(t.h2,{id:"other-changes",children:"Other changes"}),"\n",(0,r.jsx)(t.admonition,{type:"info",children:(0,r.jsx)(t.p,{children:"This section is only useful if you're a tinkerer and want to see what's going on under the hood."})}),"\n",(0,r.jsx)(t.p,{children:"The existing solution checked the bare metal metrics for how much cpu and memory was being used and how much headroom was available.\nThis is an intuitive solution but unfortunately doesnt account for when there is an external limit on the amount of resources a process can consume.\nThis is often the case in containerized environments where each container will have a quota for its cpu and memory usage."}),"\n",(0,r.jsxs)(t.p,{children:["This experiment attempts to address this issue by introducing a new ",(0,r.jsx)(t.code,{children:"isContainerized()"})," utility function and changing the way resources are collected\nwhen a container is detected."]}),"\n",(0,r.jsx)(t.admonition,{type:"note",children:(0,r.jsxs)(t.p,{children:["This ",(0,r.jsx)(t.code,{children:"isContainerized()"})," function is very similar to the existing ",(0,r.jsx)(t.code,{children:"isDocker()"})," function however for now they both work side by side.\nIf this experiment is successful, eventualy ",(0,r.jsx)(t.code,{children:"isDocker()"})," may eventually be depreciated in favour of ",(0,r.jsx)(t.code,{children:"isContainerized()"}),"."]})}),"\n",(0,r.jsx)(t.h3,{id:"cgroup-detection",children:"Cgroup detection"}),"\n",(0,r.jsxs)(t.p,{children:["On linux, to detect if cgroup is available, we check if there is a directory at ",(0,r.jsx)(t.code,{children:"/sys/fs/cgroup"}),".\nIf the directory exists, a version of cgroup is installed.\nNext we check the version of cgroup installed by checking for a directory at ",(0,r.jsx)(t.code,{children:"/sys/fs/cgroup/memory/"}),".\nIf it exists, cgroup V1 is installed. If it is missing, it is assumed cgroup V2 is installed."]}),"\n",(0,r.jsx)(t.h3,{id:"cpu-metric-collection",children:"CPU metric collection"}),"\n",(0,r.jsx)(t.p,{children:"The existing solution worked by checking the fraction of cpu idle ticks to the total number of cpu ticks since the last profile.\nIf 100000 ticks elapse and 5000 were idle, the cpu is at 95% utilisation."}),"\n",(0,r.jsxs)(t.p,{children:["In this experiment, the method of cpu load calculation depends on the result of ",(0,r.jsx)(t.code,{children:"isContainerized()"})," or if set, the ",(0,r.jsx)(t.code,{children:"CRAWLEE_CONTAINERIZED"})," environment variable.\nIf ",(0,r.jsx)(t.code,{children:"isContainerized()"}),' returns true, the new cgroup aware metric collection will be used over the "bare metal" numbers.\nThis works by inspecting the ',(0,r.jsx)(t.code,{children:"/sys/fs/cgroup/cpuacct/cpuacct.usage"}),", ",(0,r.jsx)(t.code,{children:"/sys/fs/cgroup/cpu/cpu.cfs_quota_us"})," and ",(0,r.jsx)(t.code,{children:"/sys/fs/cgroup/cpu/cpu.cfs_period_us"}),"\nfiles for cgroup V1 and the ",(0,r.jsx)(t.code,{children:"/sys/fs/cgroup/cpu.stat"})," and ",(0,r.jsx)(t.code,{children:"/sys/fs/cgroup/cpu.max"}),' files for cgroup V2.\nThe actual cpu usage figure is calculated in the same manner as the "bare metal" figure by comparing the total number of ticks elapsed to the number\nof idle ticks between profiles but by using the figures from the cgroup files.\nIf no cgroup quota is enforced, the "bare metal" numbers will be used.']}),"\n",(0,r.jsx)(t.h3,{id:"memory-metric-collection",children:"Memory metric collection"}),"\n",(0,r.jsxs)(t.p,{children:["The existing solution was already cgroup aware however an improvement has been made to memory metric collection when running on windows.\nThe existing solution used an external package ",(0,r.jsx)(t.code,{children:"apify/ps-tree"}),' to find the amount of memory crawlee and any child processes were using.\nOn Windows, this package used the depreciated "WMIC" command line utility to determine memory usage.']}),"\n",(0,r.jsxs)(t.p,{children:["In this experiment, ",(0,r.jsx)(t.code,{children:"apify/ps-tree"})," has been removed and replaced by the ",(0,r.jsx)(t.code,{children:"packages/utils/src/internals/ps-tree.ts"}),' file. This works in much the\nsame manner however, instead of using "WMIC", it uses "powershell" to collect the same data.']})]})}function u(e={}){let{wrapper:t}={...(0,s.a)(),...e.components};return t?(0,r.jsx)(t,{...e,children:(0,r.jsx)(p,{...e})}):p(e)}},47927:function(e,t,n){n.d(t,{Z:function(){return d}});var i=n(85893);n(67294);var r=n(53367),s=n(89873),o=n(87262);let[c,a]=n(99074).version.split("."),l=[c,a].join("."),d=e=>{let{to:t,children:n}=e,c=(0,s.E)(),{siteConfig:a}=(0,o.default)();return a.presets[0][1].docs.disableVersioning||c.version===l?(0,i.jsx)(r.default,{to:`/api/${t}`,children:n}):(0,i.jsx)(r.default,{to:`/api/${"current"===c.version?"next":c.version}/${t}`,children:n})}},50065:function(e,t,n){n.d(t,{Z:function(){return c},a:function(){return o}});var i=n(67294);let r={},s=i.createContext(r);function o(e){let t=i.useContext(s);return i.useMemo(function(){return"function"==typeof e?e(t):{...t,...e}},[t,e])}function c(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:o(e.components),i.createElement(s.Provider,{value:t},e.children)}},99074:function(e){e.exports=JSON.parse('{"name":"crawlee","version":"3.13.0","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","engines":{"node":">=16.0.0"},"bin":"./src/cli.ts","main":"./dist/index.js","module":"./dist/index.mjs","types":"./dist/index.d.ts","exports":{".":{"import":"./dist/index.mjs","require":"./dist/index.js","types":"./dist/index.d.ts"},"./package.json":"./package.json"},"keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"name":"Apify","email":"support@apify.com","url":"https://apify.com"},"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"license":"Apache-2.0","repository":{"type":"git","url":"git+https://github.com/apify/crawlee"},"bugs":{"url":"https://github.com/apify/crawlee/issues"},"homepage":"https://crawlee.dev","scripts":{"build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./dist/index.js ./dist/index.mjs","copy":"tsx ../../scripts/copy.ts"},"publishConfig":{"access":"public"},"dependencies":{"@crawlee/basic":"3.13.0","@crawlee/browser":"3.13.0","@crawlee/browser-pool":"3.13.0","@crawlee/cheerio":"3.13.0","@crawlee/cli":"3.13.0","@crawlee/core":"3.13.0","@crawlee/http":"3.13.0","@crawlee/jsdom":"3.13.0","@crawlee/linkedom":"3.13.0","@crawlee/playwright":"3.13.0","@crawlee/puppeteer":"3.13.0","@crawlee/utils":"3.13.0","import-local":"^3.1.0","tslib":"^2.4.0"},"peerDependencies":{"playwright":"*","puppeteer":"*"},"peerDependenciesMeta":{"playwright":{"optional":true},"puppeteer":{"optional":true}}}')}}]);