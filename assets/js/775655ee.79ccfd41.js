"use strict";(self.webpackChunk=self.webpackChunk||[]).push([["83065"],{33647:function(e,t,n){n.r(t),n.d(t,{default:()=>w,frontMatter:()=>c,metadata:()=>r,assets:()=>h,toc:()=>m,contentTitle:()=>d});var r=JSON.parse('{"id":"examples/crawl-relative-links","title":"Crawl a website with relative links","description":"When crawling a website, you may encounter different types of links present that you may want to crawl.","source":"@site/versioned_docs/version-3.4/examples/crawl_relative_links.mdx","sourceDirName":"examples","slug":"/examples/crawl-relative-links","permalink":"/docs/3.4/examples/crawl-relative-links","draft":false,"unlisted":false,"editUrl":"https://github.com/apify/crawlee/edit/master/website/versioned_docs/version-3.4/examples/crawl_relative_links.mdx","tags":[],"version":"3.4","lastUpdatedBy":"Jind\u0159ich B\xe4r","lastUpdatedAt":1686744725000,"frontMatter":{"id":"crawl-relative-links","title":"Crawl a website with relative links"},"sidebar":"docs","previous":{"title":"Crawl multiple URLs","permalink":"/docs/3.4/examples/crawl-multiple-urls"},"next":{"title":"Crawl a single URL","permalink":"/docs/3.4/examples/crawl-single-url"}}'),a=n("85893"),l=n("50065"),i=n("58168"),s=n("97645"),o=n("96199"),u=n("47927");let c={id:"crawl-relative-links",title:"Crawl a website with relative links"},d=void 0,h={},m=[];function p(e){let t={admonition:"admonition",blockquote:"blockquote",code:"code",li:"li",p:"p",ul:"ul",...(0,l.a)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsxs)(t.p,{children:["When crawling a website, you may encounter different types of links present that you may want to crawl.\nTo facilitate the easy crawling of such links, we provide the ",(0,a.jsx)(t.code,{children:"enqueueLinks()"})," method on the crawler context, which will\nautomatically find links and add them to the crawler's ",(0,a.jsx)(u.Z,{to:"core/class/RequestQueue",children:(0,a.jsx)(t.code,{children:"RequestQueue"})}),"."]}),"\n",(0,a.jsx)(t.p,{children:"We provide 3 different strategies for crawling relative links:"}),"\n",(0,a.jsxs)(t.ul,{children:["\n",(0,a.jsxs)(t.li,{children:[(0,a.jsxs)(u.Z,{to:"core/enum/EnqueueStrategy#All",children:[(0,a.jsx)("inlineCode",{children:"All"})," (or the string ",(0,a.jsx)("inlineCode",{children:'"all"'}),")"]})," which will\nenqueue all links found, regardless of the domain they point to."]}),"\n",(0,a.jsxs)(t.li,{children:[(0,a.jsxs)(u.Z,{to:"core/enum/EnqueueStrategy#SameHostname",children:[(0,a.jsx)("inlineCode",{children:"SameHostname"})," (or the string ",(0,a.jsx)("inlineCode",{children:'"same-hostname"'}),")"]})," which\nwill enqueue all links found for the same hostname. This is the default strategy."]}),"\n",(0,a.jsxs)(t.li,{children:[(0,a.jsxs)(u.Z,{to:"core/enum/EnqueueStrategy#SameDomain",children:[(0,a.jsx)("inlineCode",{children:"SameDomain"})," (or the string ",(0,a.jsx)("inlineCode",{children:'"same-domain"'}),")"]})," which\nwill enqueue all links found that have the same domain name, including links from any possible subdomain."]}),"\n"]}),"\n",(0,a.jsx)(t.admonition,{type:"note",children:(0,a.jsxs)(t.p,{children:["For these examples, we are using the ",(0,a.jsx)(u.Z,{to:"cheerio-crawler/class/CheerioCrawler",children:(0,a.jsx)(t.code,{children:"CheerioCrawler"})}),", however\nthe same method is available for both the ",(0,a.jsx)(u.Z,{to:"puppeteer-crawler/class/PuppeteerCrawler",children:(0,a.jsx)(t.code,{children:"PuppeteerCrawler"})}),"\nand ",(0,a.jsx)(u.Z,{to:"playwright-crawler/class/PlaywrightCrawler",children:(0,a.jsx)(t.code,{children:"PlaywrightCrawler"})}),", and you use it\nthe exact same way."]})}),"\n",(0,a.jsxs)(i.Z,{groupId:"enqueue_strategy",children:[(0,a.jsxs)(s.Z,{value:"all",label:"All Links",children:[(0,a.jsx)(t.admonition,{title:"Example domains",type:"note",children:(0,a.jsx)(t.p,{children:"Any urls found will be matched by this strategy, even if they go off of the site you are currently crawling."})}),(0,a.jsx)(o.default,{className:"language-js",children:"import { CheerioCrawler, EnqueueStrategy } from 'crawlee';\n\nconst crawler = new CheerioCrawler({\n    maxRequestsPerCrawl: 10, // Limitation for only 10 requests (do not use if you want to crawl all links)\n    async requestHandler({ request, enqueueLinks, log }) {\n        log.info(request.url);\n        await enqueueLinks({\n            // Setting the strategy to 'all' will enqueue all links found\n            // highlight-next-line\n            strategy: EnqueueStrategy.All,\n            // Alternatively, you can pass in the string 'all'\n            // strategy: 'all',\n        });\n    },\n});\n\n// Run the crawler with initial request\nawait crawler.run(['https://crawlee.dev']);\n"})]}),(0,a.jsxs)(s.Z,{value:"same_hostname",label:"Same Hostname",children:[(0,a.jsxs)(t.admonition,{title:"Example domains",type:"note",children:[(0,a.jsxs)(t.p,{children:["For a url of ",(0,a.jsx)(t.code,{children:"https://example.com"}),", ",(0,a.jsx)(t.code,{children:"enqueueLinks()"})," will match relative urls and urls that point to the same\nhostname."]}),(0,a.jsxs)(t.blockquote,{children:["\n",(0,a.jsxs)(t.p,{children:["This is the default strategy when calling ",(0,a.jsx)(t.code,{children:"enqueueLinks()"}),", so you don't have to specify it."]}),"\n"]}),(0,a.jsxs)(t.p,{children:["For instance, hyperlinks like ",(0,a.jsx)(t.code,{children:"https://example.com/some/path"}),", ",(0,a.jsx)(t.code,{children:"/absolute/example"})," or ",(0,a.jsx)(t.code,{children:"./relative/example"})," will all be matched by this strategy. But links to any subdomain like ",(0,a.jsx)(t.code,{children:"https://subdomain.example.com/some/path"})," won't."]})]}),(0,a.jsx)(o.default,{className:"language-js",children:"import { CheerioCrawler, EnqueueStrategy } from 'crawlee';\n\nconst crawler = new CheerioCrawler({\n    maxRequestsPerCrawl: 10, // Limitation for only 10 requests (do not use if you want to crawl all links)\n    async requestHandler({ request, enqueueLinks, log }) {\n        log.info(request.url);\n        await enqueueLinks({\n            // Setting the strategy to 'same-hostname' will enqueue all links found that are on the\n            // same hostname (including subdomain) as request.loadedUrl or request.url\n            // highlight-next-line\n            strategy: EnqueueStrategy.SameHostname,\n            // Alternatively, you can pass in the string 'same-hostname'\n            // strategy: 'same-hostname',\n        });\n    },\n});\n\n// Run the crawler with initial request\nawait crawler.run(['https://crawlee.dev']);\n"})]}),(0,a.jsxs)(s.Z,{value:"same-subdomain",label:"Same Subdomain",default:!0,children:[(0,a.jsxs)(t.admonition,{title:"Example domains",type:"note",children:[(0,a.jsxs)(t.p,{children:["For a url of ",(0,a.jsx)(t.code,{children:"https://subdomain.example.com"}),", ",(0,a.jsx)(t.code,{children:"enqueueLinks()"})," will match relative urls or urls that point to the same domain name, regardless of their subdomain."]}),(0,a.jsxs)(t.p,{children:["For instance, hyperlinks like ",(0,a.jsx)(t.code,{children:"https://subdomain.example.com/some/path"}),", ",(0,a.jsx)(t.code,{children:"/absolute/example"})," or ",(0,a.jsx)(t.code,{children:"./relative/example"})," will all be matched by this strategy, as well as links to other subdomains or to the naked domain, like ",(0,a.jsx)(t.code,{children:"https://other-subdomain.example.com"})," or ",(0,a.jsx)(t.code,{children:"https://example.com"})," will work too."]})]}),(0,a.jsx)(o.default,{className:"language-js",children:"import { CheerioCrawler, EnqueueStrategy } from 'crawlee';\n\nconst crawler = new CheerioCrawler({\n    maxRequestsPerCrawl: 10, // Limitation for only 10 requests (do not use if you want to crawl all links)\n    async requestHandler({ request, enqueueLinks, log }) {\n        log.info(request.url);\n        await enqueueLinks({\n            // Setting the strategy to 'same-domain' will enqueue all links found that are on the\n            // same hostname as request.loadedUrl or request.url\n            // highlight-next-line\n            strategy: EnqueueStrategy.SameDomain,\n            // Alternatively, you can pass in the string 'same-domain'\n            // strategy: 'same-domain',\n        });\n    },\n});\n\n// Run the crawler with initial request\nawait crawler.run(['https://crawlee.dev']);\n"})]})]})]})}function w(e={}){let{wrapper:t}={...(0,l.a)(),...e.components};return t?(0,a.jsx)(t,{...e,children:(0,a.jsx)(p,{...e})}):p(e)}},97645:function(e,t,n){n.d(t,{Z:()=>l});var r=n("85893");n("67294");var a=n("67026");function l(e){let{children:t,hidden:n,className:l}=e;return(0,r.jsx)("div",{role:"tabpanel",className:(0,a.Z)("tabItem_Ymn6",l),hidden:n,children:t})}},58168:function(e,t,n){n.d(t,{Z:()=>y});var r=n("85893"),a=n("67294"),l=n("67026"),i=n("34718"),s=n("16550"),o=n("8714"),u=n("89207"),c=n("69413"),d=n("54510");function h(e){return a.Children.toArray(e).filter(e=>"\n"!==e).map(e=>{if(!e||a.isValidElement(e)&&function(e){let{props:t}=e;return!!t&&"object"==typeof t&&"value"in t}(e))return e;throw Error(`Docusaurus error: Bad <Tabs> child <${"string"==typeof e.type?e.type:e.type.name}>: all children of the <Tabs> component should be <TabItem>, and every <TabItem> should have a unique "value" prop.`)})?.filter(Boolean)??[]}function m(e){let{value:t,tabValues:n}=e;return n.some(e=>e.value===t)}var p=n("6735");function w(e){let{className:t,block:n,selectedValue:a,selectValue:s,tabValues:o}=e,u=[],{blockElementScrollPositionUntilNextRender:c}=(0,i.o5)(),d=e=>{let t=e.currentTarget,n=o[u.indexOf(t)].value;n!==a&&(c(t),s(n))},h=e=>{let t=null;switch(e.key){case"Enter":d(e);break;case"ArrowRight":{let n=u.indexOf(e.currentTarget)+1;t=u[n]??u[0];break}case"ArrowLeft":{let n=u.indexOf(e.currentTarget)-1;t=u[n]??u[u.length-1]}}t?.focus()};return(0,r.jsx)("ul",{role:"tablist","aria-orientation":"horizontal",className:(0,l.Z)("tabs",{"tabs--block":n},t),children:o.map(e=>{let{value:t,label:n,attributes:i}=e;return(0,r.jsx)("li",{role:"tab",tabIndex:a===t?0:-1,"aria-selected":a===t,ref:e=>{u.push(e)},onKeyDown:h,onClick:d,...i,className:(0,l.Z)("tabs__item","tabItem_LNqP",i?.className,{"tabs__item--active":a===t}),children:n??t},t)})})}function f(e){let{lazy:t,children:n,selectedValue:i}=e,s=(Array.isArray(n)?n:[n]).filter(Boolean);if(t){let e=s.find(e=>e.props.value===i);return e?(0,a.cloneElement)(e,{className:(0,l.Z)("margin-top--md",e.props.className)}):null}return(0,r.jsx)("div",{className:"margin-top--md",children:s.map((e,t)=>(0,a.cloneElement)(e,{key:t,hidden:e.props.value!==i}))})}function x(e){let t=function(e){let{defaultValue:t,queryString:n=!1,groupId:r}=e,l=function(e){let{values:t,children:n}=e;return(0,a.useMemo)(()=>{let e=t??h(n).map(e=>{let{props:{value:t,label:n,attributes:r,default:a}}=e;return{value:t,label:n,attributes:r,default:a}});return!function(e){let t=(0,c.lx)(e,(e,t)=>e.value===t.value);if(t.length>0)throw Error(`Docusaurus error: Duplicate values "${t.map(e=>e.value).join(", ")}" found in <Tabs>. Every value needs to be unique.`)}(e),e},[t,n])}(e),[i,p]=(0,a.useState)(()=>(function(e){let{defaultValue:t,tabValues:n}=e;if(0===n.length)throw Error("Docusaurus error: the <Tabs> component requires at least one <TabItem> children component");if(t){if(!m({value:t,tabValues:n}))throw Error(`Docusaurus error: The <Tabs> has a defaultValue "${t}" but none of its children has the corresponding value. Available values are: ${n.map(e=>e.value).join(", ")}. If you intend to show no default tab, use defaultValue={null} instead.`);return t}let r=n.find(e=>e.default)??n[0];if(!r)throw Error("Unexpected error: 0 tabValues");return r.value})({defaultValue:t,tabValues:l})),[w,f]=function(e){let{queryString:t=!1,groupId:n}=e,r=(0,s.k6)(),l=function(e){let{queryString:t=!1,groupId:n}=e;if("string"==typeof t)return t;if(!1===t)return null;if(!0===t&&!n)throw Error('Docusaurus error: The <Tabs> component groupId prop is required if queryString=true, because this value is used as the search param name. You can also provide an explicit value such as queryString="my-search-param".');return n??null}({queryString:t,groupId:n});return[(0,u._X)(l),(0,a.useCallback)(e=>{if(!l)return;let t=new URLSearchParams(r.location.search);t.set(l,e),r.replace({...r.location,search:t.toString()})},[l,r])]}({queryString:n,groupId:r}),[x,y]=function(e){let{groupId:t}=e,n=t?`docusaurus.tab.${t}`:null,[r,l]=(0,d.Nk)(n);return[r,(0,a.useCallback)(e=>{n&&l.set(e)},[n,l])]}({groupId:r}),g=(()=>{let e=w??x;return m({value:e,tabValues:l})?e:null})();return(0,o.Z)(()=>{g&&p(g)},[g]),{selectedValue:i,selectValue:(0,a.useCallback)(e=>{if(!m({value:e,tabValues:l}))throw Error(`Can't select invalid tab value=${e}`);p(e),f(e),y(e)},[f,y,l]),tabValues:l}}(e);return(0,r.jsxs)("div",{className:(0,l.Z)("tabs-container","tabList__CuJ"),children:[(0,r.jsx)(w,{...t,...e}),(0,r.jsx)(f,{...t,...e})]})}function y(e){let t=(0,p.Z)();return(0,r.jsx)(x,{...e,children:h(e.children)},String(t))}},47927:function(e,t,n){n.d(t,{Z:function(){return c}});var r=n(85893);n(67294);var a=n(53367),l=n(89873),i=n(87262);let[s,o]=n(99074).version.split("."),u=[s,o].join("."),c=e=>{let{to:t,children:n}=e,s=(0,l.E)(),{siteConfig:o}=(0,i.default)();return o.presets[0][1].docs.disableVersioning||s.version===u?(0,r.jsx)(a.default,{to:`/api/${t}`,children:n}):(0,r.jsx)(a.default,{to:`/api/${"current"===s.version?"next":s.version}/${t}`,children:n})}},50065:function(e,t,n){n.d(t,{Z:function(){return s},a:function(){return i}});var r=n(67294);let a={},l=r.createContext(a);function i(e){let t=r.useContext(l);return r.useMemo(function(){return"function"==typeof e?e(t):{...t,...e}},[t,e])}function s(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:i(e.components),r.createElement(l.Provider,{value:t},e.children)}},99074:function(e){e.exports=JSON.parse('{"name":"crawlee","version":"3.13.0","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","engines":{"node":">=16.0.0"},"bin":"./src/cli.ts","main":"./dist/index.js","module":"./dist/index.mjs","types":"./dist/index.d.ts","exports":{".":{"import":"./dist/index.mjs","require":"./dist/index.js","types":"./dist/index.d.ts"},"./package.json":"./package.json"},"keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"name":"Apify","email":"support@apify.com","url":"https://apify.com"},"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"license":"Apache-2.0","repository":{"type":"git","url":"git+https://github.com/apify/crawlee"},"bugs":{"url":"https://github.com/apify/crawlee/issues"},"homepage":"https://crawlee.dev","scripts":{"build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./dist/index.js ./dist/index.mjs","copy":"tsx ../../scripts/copy.ts"},"publishConfig":{"access":"public"},"dependencies":{"@crawlee/basic":"3.13.0","@crawlee/browser":"3.13.0","@crawlee/browser-pool":"3.13.0","@crawlee/cheerio":"3.13.0","@crawlee/cli":"3.13.0","@crawlee/core":"3.13.0","@crawlee/http":"3.13.0","@crawlee/jsdom":"3.13.0","@crawlee/linkedom":"3.13.0","@crawlee/playwright":"3.13.0","@crawlee/puppeteer":"3.13.0","@crawlee/utils":"3.13.0","import-local":"^3.1.0","tslib":"^2.4.0"},"peerDependencies":{"playwright":"*","puppeteer":"*"},"peerDependenciesMeta":{"playwright":{"optional":true},"puppeteer":{"optional":true}}}')}}]);