"use strict";(self.webpackChunk=self.webpackChunk||[]).push([["32059"],{29350:function(e,t,r){r.r(t),r.d(t,{default:()=>g,frontMatter:()=>p,metadata:()=>n,assets:()=>c,toc:()=>h,contentTitle:()=>u});var n=JSON.parse('{"id":"examples/crawler-plugins/playwright-puppeteer-extra","title":"Using puppeteer-extra and playwright-extra","description":"puppeteer-extra and playwright-extra are community-built","source":"@site/versioned_docs/version-3.3/examples/crawler-plugins/index.mdx","sourceDirName":"examples/crawler-plugins","slug":"/examples/crawler-plugins/","permalink":"/docs/3.3/examples/crawler-plugins/","draft":false,"unlisted":false,"editUrl":"https://github.com/apify/crawlee/edit/master/website/versioned_docs/version-3.3/examples/crawler-plugins/index.mdx","tags":[],"version":"3.3","lastUpdatedBy":"Vlad Frangu","lastUpdatedAt":1678359609000,"frontMatter":{"id":"playwright-puppeteer-extra","title":"Using puppeteer-extra and playwright-extra"},"sidebar":"docs","previous":{"title":"Crawl some links on a website","permalink":"/docs/3.3/examples/crawl-some-links"},"next":{"title":"Export entire dataset to one file","permalink":"/docs/3.3/examples/export-entire-dataset"}}'),a=r("85893"),s=r("50065"),i=r("96199"),l=r("58168"),o=r("97645");r("47927");let p={id:"playwright-puppeteer-extra",title:"Using puppeteer-extra and playwright-extra"},u=void 0,c={},h=[];function d(e){let t={a:"a",admonition:"admonition",code:"code",p:"p",pre:"pre",...(0,s.a)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsxs)(t.p,{children:[(0,a.jsx)(t.a,{href:"https://www.npmjs.com/package/puppeteer-extra",target:"_blank",rel:"noopener",children:(0,a.jsx)(t.code,{children:"puppeteer-extra"})})," and ",(0,a.jsx)(t.a,{href:"https://www.npmjs.com/package/playwright-extra",target:"_blank",rel:"noopener",children:(0,a.jsx)(t.code,{children:"playwright-extra"})})," are community-built\nlibraries that bring in a plugin system to enhance the usage of ",(0,a.jsx)(t.a,{href:"https://www.npmjs.com/package/puppeteer",target:"_blank",rel:"noopener",children:(0,a.jsx)(t.code,{children:"puppeteer"})})," and\n",(0,a.jsx)(t.a,{href:"https://www.npmjs.com/package/playwright",target:"_blank",rel:"noopener",children:(0,a.jsx)(t.code,{children:"playwright"})})," respectively (bringing in extra functionality, like improving stealth for\nexample by using the ",(0,a.jsx)(t.a,{href:"https://www.npmjs.com/package/puppeteer-extra-plugin-stealth",target:"_blank",rel:"noopener",children:(0,a.jsx)(t.code,{children:"puppeteer-extra-plugin-stealth"})})," plugin)."]}),"\n",(0,a.jsxs)(t.admonition,{title:"Available plugins",type:"tip",children:[(0,a.jsxs)(t.p,{children:["You can see a list of available plugins on the ",(0,a.jsxs)(t.a,{href:"https://www.npmjs.com/package/puppeteer-extra#plugins",target:"_blank",rel:"noopener",children:[(0,a.jsx)(t.code,{children:"puppeteer-extra"}),"s plugin list"]}),"."]}),(0,a.jsxs)(t.p,{children:["For ",(0,a.jsx)(t.a,{href:"https://www.npmjs.com/package/playwright",target:"_blank",rel:"noopener",children:(0,a.jsx)(t.code,{children:"playwright"})}),", please see ",(0,a.jsxs)(t.a,{href:"https://www.npmjs.com/package/playwright-extra#plugins",target:"_blank",rel:"noopener",children:[(0,a.jsx)(t.code,{children:"playwright-extra"}),"s plugin list"]})," instead."]})]}),"\n",(0,a.jsxs)(t.p,{children:["In this example, we'll show you how to use the ",(0,a.jsx)(t.a,{href:"https://www.npmjs.com/package/puppeteer-extra-plugin-stealth",target:"_blank",rel:"noopener",children:(0,a.jsx)(t.code,{children:"puppeteer-extra-plugin-stealth"})})," plugin\nto help you avoid bot detections when crawling your target website."]}),"\n",(0,a.jsxs)(l.Z,{children:[(0,a.jsxs)(o.Z,{value:"puppeteer",label:"Puppeteer & puppeteer-extra",default:!0,children:[(0,a.jsxs)(t.admonition,{title:"Before you begin",type:"info",children:[(0,a.jsxs)(t.p,{children:["Make sure you've installed the ",(0,a.jsx)(t.code,{children:"puppeteer-extra"})," and ",(0,a.jsx)(t.code,{children:"puppeteer-extra-plugin-stealth"})," packages via your preferred package manager"]}),(0,a.jsx)(t.pre,{children:(0,a.jsx)(t.code,{className:"language-bash",children:"npm install puppeteer-extra puppeteer-extra-plugin-stealth\n"})})]}),(0,a.jsx)(t.admonition,{type:"tip",children:(0,a.jsxs)(t.p,{children:["To run this example on the Apify Platform, select the ",(0,a.jsx)(t.code,{children:"apify/actor-node-puppeteer-chrome"})," image for your Dockerfile."]})}),(0,a.jsx)(i.default,{className:"language-js",title:"src/crawler.ts",children:"import { Dataset, PuppeteerCrawler } from 'crawlee';\nimport puppeteerExtra from 'puppeteer-extra';\nimport stealthPlugin from 'puppeteer-extra-plugin-stealth';\n\n// First, we tell puppeteer-extra to use the plugin (or plugins) we want.\n// Certain plugins might have options you can pass in - read up on their documentation!\npuppeteerExtra.use(stealthPlugin());\n\n// Create an instance of the PuppeteerCrawler class - a crawler\n// that automatically loads the URLs in headless Chrome / Puppeteer.\nconst crawler = new PuppeteerCrawler({\n    launchContext: {\n        // !!! You need to specify this option to tell Crawlee to use puppeteer-extra as the launcher !!!\n        launcher: puppeteerExtra,\n        launchOptions: {\n            // Other puppeteer options work as usual\n            headless: true,\n        },\n    },\n\n    // Stop crawling after several pages\n    maxRequestsPerCrawl: 50,\n\n    // This function will be called for each URL to crawl.\n    // Here you can write the Puppeteer scripts you are familiar with,\n    // with the exception that browsers and pages are automatically managed by Crawlee.\n    // The function accepts a single parameter, which is an object with the following fields:\n    // - request: an instance of the Request class with information such as URL and HTTP method\n    // - page: Puppeteer's Page object (see https://pptr.dev/#show=api-class-page)\n    async requestHandler({ request, page, enqueueLinks, log }) {\n        log.info(`Processing ${request.url}...`);\n\n        // A function to be evaluated by Puppeteer within the browser context.\n        const data = await page.$$eval('.athing', ($posts) => {\n            const scrapedData: { title: string; rank: string; href: string }[] = [];\n\n            // We're getting the title, rank and URL of each post on Hacker News.\n            $posts.forEach(($post) => {\n                scrapedData.push({\n                    title: $post.querySelector('.title a').innerText,\n                    rank: $post.querySelector('.rank').innerText,\n                    href: $post.querySelector('.title a').href,\n                });\n            });\n\n            return scrapedData;\n        });\n\n        // Store the results to the default dataset.\n        await Dataset.pushData(data);\n\n        // Find a link to the next page and enqueue it if it exists.\n        const infos = await enqueueLinks({\n            selector: '.morelink',\n        });\n\n        if (infos.processedRequests.length === 0) log.info(`${request.url} is the last page!`);\n    },\n\n    // This function is called if the page processing failed more than maxRequestRetries+1 times.\n    failedRequestHandler({ request, log }) {\n        log.error(`Request ${request.url} failed too many times.`);\n    },\n});\n\nawait crawler.addRequests(['https://news.ycombinator.com/']);\n\n// Run the crawler and wait for it to finish.\nawait crawler.run();\n\nconsole.log('Crawler finished.');\n"})]}),(0,a.jsxs)(o.Z,{value:"playwright",label:"Playwright & playwright-extra",children:[(0,a.jsxs)(t.admonition,{title:"Before you begin",type:"info",children:[(0,a.jsxs)(t.p,{children:["Make sure you've installed the ",(0,a.jsx)(t.code,{children:"playwright-extra"})," and ",(0,a.jsx)(t.code,{children:"puppeteer-extra-plugin-stealth"})," packages via your preferred package manager"]}),(0,a.jsx)(t.pre,{children:(0,a.jsx)(t.code,{className:"language-bash",children:"npm install playwright-extra puppeteer-extra-plugin-stealth\n"})})]}),(0,a.jsx)(t.admonition,{type:"tip",children:(0,a.jsxs)(t.p,{children:["To run this example on the Apify Platform, select the ",(0,a.jsx)(t.code,{children:"apify/actor-node-puppeteer-chrome"})," image for your Dockerfile."]})}),(0,a.jsx)(i.default,{className:"language-js",title:"src/crawler.ts",children:"import { Dataset, PlaywrightCrawler } from 'crawlee';\n\n// For playwright-extra you will need to import the browser type itself that you want to use!\n// By default, PlaywrightCrawler uses chromium, but you can also use firefox or webkit.\nimport { chromium } from 'playwright-extra';\nimport stealthPlugin from 'puppeteer-extra-plugin-stealth';\n\n// First, we tell playwright-extra to use the plugin (or plugins) we want.\n// Certain plugins might have options you can pass in - read up on their documentation!\nchromium.use(stealthPlugin());\n\n// Create an instance of the PlaywrightCrawler class - a crawler\n// that automatically loads the URLs in headless Chrome / Playwright.\nconst crawler = new PlaywrightCrawler({\n    launchContext: {\n        // !!! You need to specify this option to tell Crawlee to use playwright-extra as the launcher !!!\n        launcher: chromium,\n        launchOptions: {\n            // Other playwright options work as usual\n            headless: true,\n        },\n    },\n\n    // Stop crawling after several pages\n    maxRequestsPerCrawl: 50,\n\n    // This function will be called for each URL to crawl.\n    // Here you can write the Puppeteer scripts you are familiar with,\n    // with the exception that browsers and pages are automatically managed by Crawlee.\n    // The function accepts a single parameter, which is an object with the following fields:\n    // - request: an instance of the Request class with information such as URL and HTTP method\n    // - page: Puppeteer's Page object (see https://pptr.dev/#show=api-class-page)\n    async requestHandler({ request, page, enqueueLinks, log }) {\n        log.info(`Processing ${request.url}...`);\n\n        // A function to be evaluated by Puppeteer within the browser context.\n        const data = await page.$$eval('.athing', ($posts) => {\n            const scrapedData: { title: string; rank: string; href: string }[] = [];\n\n            // We're getting the title, rank and URL of each post on Hacker News.\n            $posts.forEach(($post) => {\n                scrapedData.push({\n                    title: $post.querySelector('.title a').innerText,\n                    rank: $post.querySelector('.rank').innerText,\n                    href: $post.querySelector('.title a').href,\n                });\n            });\n\n            return scrapedData;\n        });\n\n        // Store the results to the default dataset.\n        await Dataset.pushData(data);\n\n        // Find a link to the next page and enqueue it if it exists.\n        const infos = await enqueueLinks({\n            selector: '.morelink',\n        });\n\n        if (infos.processedRequests.length === 0) log.info(`${request.url} is the last page!`);\n    },\n\n    // This function is called if the page processing failed more than maxRequestRetries+1 times.\n    failedRequestHandler({ request, log }) {\n        log.error(`Request ${request.url} failed too many times.`);\n    },\n});\n\nawait crawler.addRequests(['https://news.ycombinator.com/']);\n\n// Run the crawler and wait for it to finish.\nawait crawler.run();\n\nconsole.log('Crawler finished.');\n"})]})]})]})}function g(e={}){let{wrapper:t}={...(0,s.a)(),...e.components};return t?(0,a.jsx)(t,{...e,children:(0,a.jsx)(d,{...e})}):d(e)}},97645:function(e,t,r){r.d(t,{Z:()=>s});var n=r("85893");r("67294");var a=r("67026");function s(e){let{children:t,hidden:r,className:s}=e;return(0,n.jsx)("div",{role:"tabpanel",className:(0,a.Z)("tabItem_Ymn6",s),hidden:r,children:t})}},58168:function(e,t,r){r.d(t,{Z:()=>x});var n=r("85893"),a=r("67294"),s=r("67026"),i=r("34718"),l=r("16550"),o=r("8714"),p=r("89207"),u=r("69413"),c=r("54510");function h(e){return a.Children.toArray(e).filter(e=>"\n"!==e).map(e=>{if(!e||a.isValidElement(e)&&function(e){let{props:t}=e;return!!t&&"object"==typeof t&&"value"in t}(e))return e;throw Error(`Docusaurus error: Bad <Tabs> child <${"string"==typeof e.type?e.type:e.type.name}>: all children of the <Tabs> component should be <TabItem>, and every <TabItem> should have a unique "value" prop.`)})?.filter(Boolean)??[]}function d(e){let{value:t,tabValues:r}=e;return r.some(e=>e.value===t)}var g=r("6735");function m(e){let{className:t,block:r,selectedValue:a,selectValue:l,tabValues:o}=e,p=[],{blockElementScrollPositionUntilNextRender:u}=(0,i.o5)(),c=e=>{let t=e.currentTarget,r=o[p.indexOf(t)].value;r!==a&&(u(t),l(r))},h=e=>{let t=null;switch(e.key){case"Enter":c(e);break;case"ArrowRight":{let r=p.indexOf(e.currentTarget)+1;t=p[r]??p[0];break}case"ArrowLeft":{let r=p.indexOf(e.currentTarget)-1;t=p[r]??p[p.length-1]}}t?.focus()};return(0,n.jsx)("ul",{role:"tablist","aria-orientation":"horizontal",className:(0,s.Z)("tabs",{"tabs--block":r},t),children:o.map(e=>{let{value:t,label:r,attributes:i}=e;return(0,n.jsx)("li",{role:"tab",tabIndex:a===t?0:-1,"aria-selected":a===t,ref:e=>{p.push(e)},onKeyDown:h,onClick:c,...i,className:(0,s.Z)("tabs__item","tabItem_LNqP",i?.className,{"tabs__item--active":a===t}),children:r??t},t)})})}function w(e){let{lazy:t,children:r,selectedValue:i}=e,l=(Array.isArray(r)?r:[r]).filter(Boolean);if(t){let e=l.find(e=>e.props.value===i);return e?(0,a.cloneElement)(e,{className:(0,s.Z)("margin-top--md",e.props.className)}):null}return(0,n.jsx)("div",{className:"margin-top--md",children:l.map((e,t)=>(0,a.cloneElement)(e,{key:t,hidden:e.props.value!==i}))})}function f(e){let t=function(e){let{defaultValue:t,queryString:r=!1,groupId:n}=e,s=function(e){let{values:t,children:r}=e;return(0,a.useMemo)(()=>{let e=t??h(r).map(e=>{let{props:{value:t,label:r,attributes:n,default:a}}=e;return{value:t,label:r,attributes:n,default:a}});return!function(e){let t=(0,u.lx)(e,(e,t)=>e.value===t.value);if(t.length>0)throw Error(`Docusaurus error: Duplicate values "${t.map(e=>e.value).join(", ")}" found in <Tabs>. Every value needs to be unique.`)}(e),e},[t,r])}(e),[i,g]=(0,a.useState)(()=>(function(e){let{defaultValue:t,tabValues:r}=e;if(0===r.length)throw Error("Docusaurus error: the <Tabs> component requires at least one <TabItem> children component");if(t){if(!d({value:t,tabValues:r}))throw Error(`Docusaurus error: The <Tabs> has a defaultValue "${t}" but none of its children has the corresponding value. Available values are: ${r.map(e=>e.value).join(", ")}. If you intend to show no default tab, use defaultValue={null} instead.`);return t}let n=r.find(e=>e.default)??r[0];if(!n)throw Error("Unexpected error: 0 tabValues");return n.value})({defaultValue:t,tabValues:s})),[m,w]=function(e){let{queryString:t=!1,groupId:r}=e,n=(0,l.k6)(),s=function(e){let{queryString:t=!1,groupId:r}=e;if("string"==typeof t)return t;if(!1===t)return null;if(!0===t&&!r)throw Error('Docusaurus error: The <Tabs> component groupId prop is required if queryString=true, because this value is used as the search param name. You can also provide an explicit value such as queryString="my-search-param".');return r??null}({queryString:t,groupId:r});return[(0,p._X)(s),(0,a.useCallback)(e=>{if(!s)return;let t=new URLSearchParams(n.location.search);t.set(s,e),n.replace({...n.location,search:t.toString()})},[s,n])]}({queryString:r,groupId:n}),[f,x]=function(e){let{groupId:t}=e,r=t?`docusaurus.tab.${t}`:null,[n,s]=(0,c.Nk)(r);return[n,(0,a.useCallback)(e=>{r&&s.set(e)},[r,s])]}({groupId:n}),y=(()=>{let e=m??f;return d({value:e,tabValues:s})?e:null})();return(0,o.Z)(()=>{y&&g(y)},[y]),{selectedValue:i,selectValue:(0,a.useCallback)(e=>{if(!d({value:e,tabValues:s}))throw Error(`Can't select invalid tab value=${e}`);g(e),w(e),x(e)},[w,x,s]),tabValues:s}}(e);return(0,n.jsxs)("div",{className:(0,s.Z)("tabs-container","tabList__CuJ"),children:[(0,n.jsx)(m,{...t,...e}),(0,n.jsx)(w,{...t,...e})]})}function x(e){let t=(0,g.Z)();return(0,n.jsx)(f,{...e,children:h(e.children)},String(t))}},47927:function(e,t,r){r.d(t,{Z:function(){return u}});var n=r(85893);r(67294);var a=r(53367),s=r(89873),i=r(87262);let[l,o]=r(99074).version.split("."),p=[l,o].join("."),u=e=>{let{to:t,children:r}=e,l=(0,s.E)(),{siteConfig:o}=(0,i.default)();return o.presets[0][1].docs.disableVersioning||l.version===p?(0,n.jsx)(a.default,{to:`/api/${t}`,children:r}):(0,n.jsx)(a.default,{to:`/api/${"current"===l.version?"next":l.version}/${t}`,children:r})}},50065:function(e,t,r){r.d(t,{Z:function(){return l},a:function(){return i}});var n=r(67294);let a={},s=n.createContext(a);function i(e){let t=n.useContext(s);return n.useMemo(function(){return"function"==typeof e?e(t):{...t,...e}},[t,e])}function l(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:i(e.components),n.createElement(s.Provider,{value:t},e.children)}},99074:function(e){e.exports=JSON.parse('{"name":"crawlee","version":"3.13.0","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","engines":{"node":">=16.0.0"},"bin":"./src/cli.ts","main":"./dist/index.js","module":"./dist/index.mjs","types":"./dist/index.d.ts","exports":{".":{"import":"./dist/index.mjs","require":"./dist/index.js","types":"./dist/index.d.ts"},"./package.json":"./package.json"},"keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"name":"Apify","email":"support@apify.com","url":"https://apify.com"},"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"license":"Apache-2.0","repository":{"type":"git","url":"git+https://github.com/apify/crawlee"},"bugs":{"url":"https://github.com/apify/crawlee/issues"},"homepage":"https://crawlee.dev","scripts":{"build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./dist/index.js ./dist/index.mjs","copy":"tsx ../../scripts/copy.ts"},"publishConfig":{"access":"public"},"dependencies":{"@crawlee/basic":"3.13.0","@crawlee/browser":"3.13.0","@crawlee/browser-pool":"3.13.0","@crawlee/cheerio":"3.13.0","@crawlee/cli":"3.13.0","@crawlee/core":"3.13.0","@crawlee/http":"3.13.0","@crawlee/jsdom":"3.13.0","@crawlee/linkedom":"3.13.0","@crawlee/playwright":"3.13.0","@crawlee/puppeteer":"3.13.0","@crawlee/utils":"3.13.0","import-local":"^3.1.0","tslib":"^2.4.0"},"peerDependencies":{"playwright":"*","puppeteer":"*"},"peerDependenciesMeta":{"playwright":{"optional":true},"puppeteer":{"optional":true}}}')}}]);