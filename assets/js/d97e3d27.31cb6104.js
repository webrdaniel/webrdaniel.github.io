"use strict";(self.webpackChunk=self.webpackChunk||[]).push([["4602"],{47235:function(e,r,i){i.r(r),i.d(r,{assets:function(){return l},contentTitle:function(){return a},default:function(){return h},frontMatter:function(){return n},metadata:function(){return t},toc:function(){return c}});var t=i(99814),o=i(85893),s=i(50065);let n={slug:"proxy-management-in-crawlee",title:"How Crawlee uses tiered proxies to avoid getting blocked",tags:["proxy"],description:"Find out how Crawlee\u2019s tiered proxy system rotates between different types of proxies to control web scraping costs and avoid getting blocked.",image:"./img/tiered-proxies.webp",authors:["SauravJ"]},a=void 0,l={image:i(6555).Z,authorsImageUrls:[void 0]},c=[{value:"What are tiered proxies?",id:"what-are-tiered-proxies",level:2},{value:"Features:",id:"features",level:2},{value:"Working",id:"working",level:2},{value:"Usage",id:"usage",level:2},{value:"How tiered proxies use Session Pool under the hood",id:"how-tiered-proxies-use-session-pool-under-the-hood",level:2},{value:"Conclusion: using proxies efficiently",id:"conclusion-using-proxies-efficiently",level:2}];function d(e){let r={a:"a",admonition:"admonition",code:"code",h2:"h2",img:"img",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,s.a)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(r.p,{children:"Hello Crawlee community,"}),"\n",(0,o.jsx)(r.p,{children:"We are back with another blog, this time explaining how Crawlee rotates proxies and prevents crawlers from getting blocked."}),"\n",(0,o.jsxs)(r.p,{children:["Proxies vary in quality, speed, reliability, and cost. There are a ",(0,o.jsx)(r.a,{href:"https://blog.apify.com/types-of-proxies/",children:"few types of proxies"}),", such as datacenter and residential proxies. Datacenter proxies are cheaper but, on the other hand, more prone to getting blocked, and vice versa with residential proxies."]}),"\n",(0,o.jsxs)(r.p,{children:["It is hard for developers to decide which proxy to use while scraping data. We might get blocked if we use ",(0,o.jsx)(r.a,{href:"https://blog.apify.com/datacenter-proxies-when-to-use-them-and-how-to-make-the-most-of-them/",children:"datacenter proxies"})," for low-cost scraping, but residential proxies are sometimes too expensive for bigger projects. Developers need a system that can manage both costs and avoid getting blocked. To manage this, we recently introduced tiered proxies in Crawlee. Let\u2019s take a look at it."]}),"\n",(0,o.jsx)(r.admonition,{type:"note",children:(0,o.jsxs)(r.p,{children:["If you like reading this blog, we would be really happy if you gave ",(0,o.jsx)(r.a,{href:"https://github.com/apify/crawlee/",children:"Crawlee a star on GitHub!"})]})}),"\n",(0,o.jsx)(r.h2,{id:"what-are-tiered-proxies",children:"What are tiered proxies?"}),"\n",(0,o.jsx)(r.p,{children:"Tiered proxies are a method of organizing and using different types of proxies based on their quality, speed, reliability, and cost. Tiered proxies allow you to rotate between a mix of proxy types to optimize your scraping activities."}),"\n",(0,o.jsx)(r.p,{children:"You categorize your proxies into different tiers based on their quality. For example:"}),"\n",(0,o.jsxs)(r.ul,{children:["\n",(0,o.jsxs)(r.li,{children:[(0,o.jsx)(r.strong,{children:"High-tier proxies"}),": Fast, reliable, and expensive. Best for critical tasks where you need high performance."]}),"\n",(0,o.jsxs)(r.li,{children:[(0,o.jsx)(r.strong,{children:"Mid-tier proxies"}),": Moderate speed and reliability. A good balance between cost and performance."]}),"\n",(0,o.jsxs)(r.li,{children:[(0,o.jsx)(r.strong,{children:"Low-tier proxies"}),": Slow and less reliable but cheap. Useful for less critical tasks or high-volume scraping."]}),"\n"]}),"\n",(0,o.jsx)(r.h2,{id:"features",children:"Features:"}),"\n",(0,o.jsxs)(r.ul,{children:["\n",(0,o.jsxs)(r.li,{children:[(0,o.jsx)(r.strong,{children:"Tracking errors"}),": The system monitors errors (e.g. failed requests, retries) for each domain."]}),"\n",(0,o.jsxs)(r.li,{children:[(0,o.jsx)(r.strong,{children:"Adjusting tiers"}),": Higher-tier proxies are used if a domain shows more errors. Conversely, if a domain performs well with a high-tier proxy, the system will occasionally test lower-tier proxies. If successful, it continues using the lower tier, optimizing costs."]}),"\n",(0,o.jsxs)(r.li,{children:[(0,o.jsx)(r.strong,{children:"Forgetting old errors"}),": Old errors are given less weight over time, allowing the system to adjust tiers dynamically as proxies' performance changes."]}),"\n"]}),"\n",(0,o.jsx)(r.h2,{id:"working",children:"Working"}),"\n",(0,o.jsxs)(r.p,{children:["The ",(0,o.jsx)(r.code,{children:"tieredProxyUrls"})," option in Crawlee's ",(0,o.jsx)(r.code,{children:"ProxyConfigurationOptions"})," allows you to define a list of proxy URLs organized into tiers. Each tier represents a different level of quality, speed, and reliability."]}),"\n",(0,o.jsx)(r.h2,{id:"usage",children:"Usage"}),"\n",(0,o.jsxs)(r.p,{children:[(0,o.jsx)(r.strong,{children:"Fallback Mechanism"}),": Crawlee starts with the first tier of proxies. If proxies in the current tier fail, it will switch to the next tier."]}),"\n",(0,o.jsx)(r.pre,{children:(0,o.jsx)(r.code,{className:"language-js",children:"import { CheerioCrawler, ProxyConfiguration } from 'crawlee';\n\nconst proxyConfiguration = new ProxyConfiguration({\n    tieredProxyUrls: [\n        ['http://tier1-proxy1.example.com', 'http://tier1-proxy2.example.com'],\n        ['http://tier2-proxy1.example.com', 'http://tier2-proxy2.example.com'],\n        ['http://tier2-proxy1.example.com', 'http://tier3-proxy2.example.com'],\n    ],\n});\n\nconst crawler = new CheerioCrawler({\n    proxyConfiguration,\n    requestHandler: async ({ request, response }) => {\n        // Handle the request\n    },\n});\n\nawait crawler.addRequests([\n    { url: 'https://example.com/critical' },\n    { url: 'https://example.com/important' },\n    { url: 'https://example.com/regular' },\n]);\n\nawait crawler.run();\n"})}),"\n",(0,o.jsx)(r.h2,{id:"how-tiered-proxies-use-session-pool-under-the-hood",children:"How tiered proxies use Session Pool under the hood"}),"\n",(0,o.jsxs)(r.p,{children:["A session pool is a way to manage multiple ",(0,o.jsx)(r.a,{href:"https://crawlee.dev/api/core/class/Session",children:"sessions"})," on a website so you can distribute your requests across them, reducing the chances of being detected and blocked. You can imagine each session like a different human user with its own IP address."]}),"\n",(0,o.jsxs)(r.p,{children:["When you use tiered proxies, each proxy tier works with the ",(0,o.jsx)(r.a,{href:"https://crawlee.dev/api/core/class/SessionPool",children:"session pool"})," to enhance request distribution and manage errors effectively."]}),"\n",(0,o.jsx)(r.p,{children:(0,o.jsx)(r.img,{alt:"Diagram explaining how tiered proxies use Session Pool under the hood",src:i(8382).Z+"",width:"1536",height:"864"})}),"\n",(0,o.jsxs)(r.p,{children:["For each request, the crawler instance asks the ",(0,o.jsx)(r.code,{children:"ProxyConfiguration"})," which proxy it should use. ' ProxyConfiguration` also keeps track of the requests domains, and if it sees more requests being retried or, say, more errors, it returns higher proxy tiers."]}),"\n",(0,o.jsxs)(r.p,{children:["In each request, we must pass ",(0,o.jsx)(r.code,{children:"sessionId"})," and the request URL to the proxy configuration to get the needed proxy URL from one of the tiers."]}),"\n",(0,o.jsx)(r.p,{children:"Choosing which session to pass is where SessionPool comes in. Session pool automatically creates a pool of sessions, rotates them, and uses one of them without getting blocked and mimicking human-like behavior."}),"\n",(0,o.jsx)(r.h2,{id:"conclusion-using-proxies-efficiently",children:"Conclusion: using proxies efficiently"}),"\n",(0,o.jsxs)(r.p,{children:["This inbuilt feature is similar to what Scrapy's ",(0,o.jsx)(r.code,{children:"scrapy-rotating-proxies"})," plugin offers to its users. The tiered proxy configuration dynamically adjusts proxy usage based on real-time performance data, optimizing cost and performance. The session pool ensures requests are distributed across multiple sessions, mimicking human behavior and reducing detection risk."]}),"\n",(0,o.jsx)(r.p,{children:"We hope this gives you a better understanding of how Crawlee manages proxies and sessions to make your scraping tasks more effective."}),"\n",(0,o.jsxs)(r.p,{children:["As always, we welcome your feedback. ",(0,o.jsx)(r.a,{href:"https://apify.com/discord",children:"Join our developer community on Discord"})," to ask any questions about Crawlee or tell us how you use it."]})]})}function h(e={}){let{wrapper:r}={...(0,s.a)(),...e.components};return r?(0,o.jsx)(r,{...e,children:(0,o.jsx)(d,{...e})}):d(e)}},6555:function(e,r,i){i.d(r,{Z:function(){return t}});let t=i.p+"assets/images/tiered-proxies-b18bb59e60cee3551f788b1114066666.webp"},8382:function(e,r,i){i.d(r,{Z:function(){return t}});let t=i.p+"assets/images/session-pool-working-a2dee3e83a3444b1330081044b0a234a.webp"},50065:function(e,r,i){i.d(r,{Z:function(){return a},a:function(){return n}});var t=i(67294);let o={},s=t.createContext(o);function n(e){let r=t.useContext(s);return t.useMemo(function(){return"function"==typeof e?e(r):{...r,...e}},[r,e])}function a(e){let r;return r=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:n(e.components),t.createElement(s.Provider,{value:r},e.children)}},99814:function(e){e.exports=JSON.parse('{"permalink":"/blog/proxy-management-in-crawlee","source":"@site/blog/2024/06-24-proxy-management-in-crawlee/index.md","title":"How Crawlee uses tiered proxies to avoid getting blocked","description":"Find out how Crawlee\u2019s tiered proxy system rotates between different types of proxies to control web scraping costs and avoid getting blocked.","date":"2024-06-24T00:00:00.000Z","tags":[{"inline":true,"label":"proxy","permalink":"/blog/tags/proxy"}],"readingTime":3.68,"hasTruncateMarker":true,"authors":[{"name":"Saurav Jain","title":"Developer Community Manager","url":"https://github.com/souravjain540","socials":{"x":"https://x.com/sauain","github":"https://github.com/souravjain540"},"imageURL":"https://avatars.githubusercontent.com/u/53312820?v=4","key":"SauravJ","page":null}],"frontMatter":{"slug":"proxy-management-in-crawlee","title":"How Crawlee uses tiered proxies to avoid getting blocked","tags":["proxy"],"description":"Find out how Crawlee\u2019s tiered proxy system rotates between different types of proxies to control web scraping costs and avoid getting blocked.","image":"./img/tiered-proxies.webp","authors":["SauravJ"]},"unlisted":false,"prevItem":{"title":"Announcing Crawlee for Python: Now you can use Python to build reliable web crawlers","permalink":"/blog/launching-crawlee-python"},"nextItem":{"title":"Building a Netflix show recommender using Crawlee and React","permalink":"/blog/netflix-show-recommender"}}')}}]);