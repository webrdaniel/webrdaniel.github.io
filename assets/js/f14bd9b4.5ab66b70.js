"use strict";(self.webpackChunk=self.webpackChunk||[]).push([["12261"],{4587:function(e,n,t){t.r(n),t.d(n,{assets:function(){return l},contentTitle:function(){return s},default:function(){return h},frontMatter:function(){return o},metadata:function(){return i},toc:function(){return c}});var i=t(14883),r=t(85893),a=t(50065);let o={slug:"linkedin-job-scraper-python",title:"How to create a LinkedIn job scraper in Python with Crawlee",description:"Learn how to scrape LinkedIn jobs and save it into a CSV file using Python.",image:"./img/linkedin-job-scraper.webp",authors:["ArindamM"]},s="How to create a LinkedIn job scraper in Python with Crawlee",l={image:t(71573).Z,authorsImageUrls:[void 0]},c=[{value:"Introduction",id:"introduction",level:2},{value:"Prerequisites",id:"prerequisites",level:2},{value:"Building the LinkedIn job Scraper in Python with Crawlee",id:"building-the-linkedin-job-scraper-in-python-with-crawlee",level:2},{value:"1. Inspecting the LinkedIn job Search Page",id:"1-inspecting-the-linkedin-job-search-page",level:3},{value:"2. Routing your crawler",id:"2-routing-your-crawler",level:3},{value:"3. Creating your application",id:"3-creating-your-application",level:2},{value:"4. Testing your app",id:"4-testing-your-app",level:2},{value:"Conclusion",id:"conclusion",level:2}];function d(e){let n={a:"a",admonition:"admonition",code:"code",h2:"h2",h3:"h3",img:"img",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,a.a)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.h2,{id:"introduction",children:"Introduction"}),"\n",(0,r.jsx)(n.p,{children:"In this article, we will build a web application that scrapes LinkedIn for job postings using Crawlee and Streamlit."}),"\n",(0,r.jsx)(n.p,{children:"We will create a LinkedIn job scraper in Python using Crawlee for Python to extract the company name, job title, time of posting, and link to the job posting from dynamically received user input through the web application."}),"\n",(0,r.jsx)(n.admonition,{type:"note",children:(0,r.jsxs)(n.p,{children:["One of our community members wrote this blog as a contribution to Crawlee Blog. If you want to contribute blogs like these to Crawlee Blog, please reach out to us on our ",(0,r.jsx)(n.a,{href:"https://apify.com/discord",children:"discord channel"}),"."]})}),"\n",(0,r.jsx)(n.p,{children:"By the end of this tutorial, you\u2019ll have a fully functional web application that you can use to scrape job postings from LinkedIn."}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{alt:"Linkedin Job Scraper",src:t(27388).Z+"",width:"1628",height:"733"})}),"\n",(0,r.jsx)(n.p,{children:"Let's begin."}),"\n",(0,r.jsx)(n.h2,{id:"prerequisites",children:"Prerequisites"}),"\n",(0,r.jsx)(n.p,{children:"Let's start by creating a new Crawlee for Python project with this command:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"pipx run crawlee create linkedin-scraper\n"})}),"\n",(0,r.jsxs)(n.p,{children:["Select ",(0,r.jsx)(n.code,{children:"PlaywrightCrawler"})," in the terminal when Crawlee asks for it."]}),"\n",(0,r.jsxs)(n.p,{children:["After installation, Crawlee for Python will create boilerplate code for you. You can change the directory(",(0,r.jsx)(n.code,{children:"cd"}),") to the project folder and run this command to install dependencies."]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"poetry install\n"})}),"\n",(0,r.jsx)(n.p,{children:"We are going to begin editing the files provided to us by Crawlee so we can build our scraper."}),"\n",(0,r.jsx)(n.admonition,{type:"note",children:(0,r.jsxs)(n.p,{children:["Before going ahead if you like reading this blog, we would be really happy if you gave ",(0,r.jsx)(n.a,{href:"https://github.com/apify/crawlee-python/",children:"Crawlee for Python a star on GitHub"}),"!"]})}),"\n",(0,r.jsx)(n.h2,{id:"building-the-linkedin-job-scraper-in-python-with-crawlee",children:"Building the LinkedIn job Scraper in Python with Crawlee"}),"\n",(0,r.jsxs)(n.p,{children:["In this section, we will be building the scraper using the Crawlee for Python package. To learn more about Crawlee, check out their ",(0,r.jsx)(n.a,{href:"https://www.crawlee.dev/python/docs/quick-start",children:"documentation"}),"."]}),"\n",(0,r.jsx)(n.h3,{id:"1-inspecting-the-linkedin-job-search-page",children:"1. Inspecting the LinkedIn job Search Page"}),"\n",(0,r.jsx)(n.p,{children:"Open LinkedIn in your web browser and sign out from the website (if you already have an account logged in). You should see an interface like this."}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{alt:"LinkedIn Homepage",src:t(97341).Z+"",width:"1432",height:"723"})}),"\n",(0,r.jsx)(n.p,{children:"Navigate to the jobs section, search for a job and location of your choice, and copy the URL."}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{alt:"LinkedIn Jobs Page",src:t(18393).Z+"",width:"1372",height:"728"})}),"\n",(0,r.jsx)(n.p,{children:"You should have something like this:"}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.code,{children:"https://www.linkedin.com/jobs/search?keywords=Backend%20Developer&location=Canada&geoId=101174742&trk=public_jobs_jobs-search-bar_search-submit&position=1&pageNum=0"})}),"\n",(0,r.jsx)(n.p,{children:"We're going to focus on the search parameters, which is the part that goes after '?'. The keyword and location parameters are the most important ones for us."}),"\n",(0,r.jsxs)(n.p,{children:["The job title the user supplies will be input to the keyword parameter, while the location the user supplies will go into the location parameter. Lastly, the ",(0,r.jsx)(n.code,{children:"geoId"})," parameter will be removed while we keep the other parameters constant."]}),"\n",(0,r.jsxs)(n.p,{children:["We are going to be making changes to our ",(0,r.jsx)(n.code,{children:"main.py"})," file. Copy and paste the code below in your ",(0,r.jsx)(n.code,{children:"main.py"})," file."]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-py",children:'from crawlee.playwright_crawler import PlaywrightCrawler\nfrom .routes import router\nimport urllib.parse\n\nasync def main(title: str, location: str, data_name: str) -> None:\n    base_url = "https://www.linkedin.com/jobs/search"\n\n    # URL encode the parameters\n    params = {\n        "keywords": title,\n        "location": location,\n        "trk": "public_jobs_jobs-search-bar_search-submit",\n        "position": "1",\n        "pageNum": "0"\n    }\n\n    encoded_params = urlencode(params)\n\n    # Encode parameters into a query string\n    query_string = \'?\' + encoded_params\n\n    # Combine base URL with the encoded query string\n    encoded_url = urljoin(base_url, "") + query_string\n\n    # Initialize the crawler\n    crawler = PlaywrightCrawler(\n        request_handler=router,\n    )\n\n    # Run the crawler with the initial list of URLs\n    await crawler.run([encoded_url])\n\n    # Save the data in a CSV file\n    output_file = f"{data_name}.csv"\n    await crawler.export_data(output_file)\n'})}),"\n",(0,r.jsx)(n.p,{children:"Now that we have encoded the URL, the next step for us is to adjust the generated router to handle LinkedIn job postings."}),"\n",(0,r.jsx)(n.h3,{id:"2-routing-your-crawler",children:"2. Routing your crawler"}),"\n",(0,r.jsx)(n.p,{children:"We will be making use of two handlers for your application:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.strong,{children:"Default handler"})}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:["The ",(0,r.jsx)(n.code,{children:"default_handler"})," handles the start URL"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.strong,{children:"Job listing"})}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:["The ",(0,r.jsx)(n.code,{children:"job_listing"})," handler extracts the individual job details."]}),"\n",(0,r.jsx)(n.p,{children:"Playwright crawler is going to crawl through the job posting page and extract the links to all job postings on the page."}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{alt:"Identifying elements",src:t(83938).Z+"",width:"1435",height:"727"})}),"\n",(0,r.jsxs)(n.p,{children:["When you examine the job postings, you will discover that the job posting links are inside an ordered list with a class named ",(0,r.jsx)(n.code,{children:"jobs-search__results-list"}),". We will then extract the links using the Playwright locator object and add them to the ",(0,r.jsx)(n.code,{children:"job_listing"})," route for processing."]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-py",children:'router = Router[PlaywrightCrawlingContext]()\n\n@router.default_handler\nasync def default_handler(context: PlaywrightCrawlingContext) -> None:\n    """Default request handler."""\n\n    #select all the links for the job posting on the page\n    hrefs = await context.page.locator(\'ul.jobs-search__results-list a\').evaluate_all("links => links.map(link => link.href)")\n\n    #add all the links to the job listing route\n    await context.add_requests(\n            [Request.from_url(rec, label=\'job_listing\') for rec in hrefs]\n        )\n'})}),"\n",(0,r.jsx)(n.p,{children:"Now that we have the job listings, the next step is to scrape their details."}),"\n",(0,r.jsx)(n.p,{children:"We'll extract each job\u2019s title, company's name, time of posting, and the link to the job post. Open your dev tools to extract each element using its CSS selector."}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{alt:"Inspecting elements",src:t(5571).Z+"",width:"1440",height:"733"})}),"\n",(0,r.jsxs)(n.p,{children:["After scraping each of the listings, we'll remove special characters from the text to make it clean and push the data to local storage using the ",(0,r.jsx)(n.code,{children:"context.push_data"})," function."]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-py",children:"@router.handler('job_listing')\nasync def listing_handler(context: PlaywrightCrawlingContext) -> None:\n    \"\"\"Handler for job listings.\"\"\"\n\n    await context.page.wait_for_load_state('load')\n\n    job_title = await context.page.locator('div.top-card-layout__entity-info h1.top-card-layout__title').text_content()\n\n    company_name  = await context.page.locator('span.topcard__flavor a').text_content()\n\n    time_of_posting= await context.page.locator('div.topcard__flavor-row span.posted-time-ago__text').text_content()\n\n\n    await context.push_data(\n        {\n            # we are making use of regex to remove special characters for the extracted texts\n\n            'title': re.sub(r'[\\s\\n]+', '', job_title),\n            'Company name': re.sub(r'[\\s\\n]+', '', company_name),\n            'Time of posting': re.sub(r'[\\s\\n]+', '', time_of_posting),\n            'url': context.request.loaded_url,\n        }\n    )\n"})}),"\n",(0,r.jsx)(n.h2,{id:"3-creating-your-application",children:"3. Creating your application"}),"\n",(0,r.jsxs)(n.p,{children:["For this project, we will be using Streamlit for the web application. Before we proceed, we are going to create a new file named ",(0,r.jsx)(n.code,{children:"app.py"})," in your project directory. In addition, ensure you have  ",(0,r.jsx)(n.a,{href:"https://docs.streamlit.io/get-started/installation",children:"Streamlit"}),"  installed in your global Python environment before proceeding with this section."]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-py",children:'import streamlit as st\nimport subprocess\n\n# Streamlit form for inputs\nst.title("LinkedIn Job Scraper")\n\nwith st.form("scraper_form"):\n    title = st.text_input("Job Title", value="backend developer")\n    location = st.text_input("Job Location", value="newyork")\n    data_name = st.text_input("Output File Name", value="backend_jobs")\n\n    submit_button = st.form_submit_button("Run Scraper")\n\nif submit_button:\n\n    # Run the scraping script with the form inputs\n    command = f"""poetry run python -m linkedin-scraper --title "{title}"  --location "{location}" --data_name "{data_name}" """\n\n    with st.spinner("Crawling in progress..."):\n         # Execute the command and display the results\n        result = subprocess.run(command, shell=True, capture_output=True, text=True)\n\n        st.write("Script Output:")\n        st.text(result.stdout)\n\n        if result.returncode == 0:\n            st.success(f"Data successfully saved in {data_name}.csv")\n        else:\n            st.error(f"Error: {result.stderr}")\n'})}),"\n",(0,r.jsx)(n.p,{children:"The Streamlit web application takes in the user's input and uses the Python Subprocess package to run the Crawlee scraping script."}),"\n",(0,r.jsx)(n.h2,{id:"4-testing-your-app",children:"4. Testing your app"}),"\n",(0,r.jsxs)(n.p,{children:["Before we test the application, we need to make a little modification to the ",(0,r.jsx)(n.code,{children:"__main__"})," file in order for it to accommodate the command line arguments."]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-py",children:'import asyncio\nimport argparse\n\nfrom .main import main\n\ndef get_args():\n    # ArgumentParser object to capture command-line arguments\n    parser = argparse.ArgumentParser(description="Crawl LinkedIn job listings")\n\n\n    # Define the arguments\n    parser.add_argument("--title", type=str, required=True, help="Job title")\n    parser.add_argument("--location", type=str, required=True, help="Job location")\n    parser.add_argument("--data_name", type=str, required=True, help="Name for the output CSV file")\n\n\n    # Parse the arguments\n    return parser.parse_args()\n\nif __name__ == \'__main__\':\n    args = get_args()\n    # Run the main function with the parsed command-line arguments\n    asyncio.run(main(args.title, args.location, args.data_name))\n'})}),"\n",(0,r.jsx)(n.p,{children:"We will start the Streamlit application by running this code in the terminal:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"streamlit run app.py\n"})}),"\n",(0,r.jsx)(n.p,{children:"This is what your application what the application should look like on the browser:"}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{alt:"Running scraper",src:t(254).Z+"",width:"1607",height:"730"})}),"\n",(0,r.jsx)(n.p,{children:"You will get this interface showing you that the scraping has been completed:"}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{alt:"Filling input form",src:t(37272).Z+"",width:"1602",height:"725"})}),"\n",(0,r.jsx)(n.p,{children:"To access the scraped data, go over to your project directory and open the CSV file."}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{alt:"CSV file with all scraped LinkedIn jobs",src:t(10051).Z+"",width:"1482",height:"725"})}),"\n",(0,r.jsx)(n.p,{children:"You should have something like this as the output of your CSV file."}),"\n",(0,r.jsx)(n.h2,{id:"conclusion",children:"Conclusion"}),"\n",(0,r.jsx)(n.p,{children:"In this tutorial, we have learned how to build an application that can scrape job posting data from LinkedIn using Crawlee. Have fun building great scraping applications with Crawlee."}),"\n",(0,r.jsxs)(n.p,{children:["You can find the complete working Crawler code here on the ",(0,r.jsx)(n.a,{href:"https://github.com/Arindam200/LinkedIn_Scraping",children:"GitHub repository."})]})]})}function h(e={}){let{wrapper:n}={...(0,a.a)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(d,{...e})}):d(e)}},71573:function(e,n,t){t.d(n,{Z:function(){return i}});let i=t.p+"assets/images/linkedin-job-scraper-3490f5b2fd530a5ee7a74cda78c6f0e7.webp"},83938:function(e,n,t){t.d(n,{Z:function(){return i}});let i=t.p+"assets/images/elements-a634b50a7ad31ae15db61e1a06f5125e.webp"},10051:function(e,n,t){t.d(n,{Z:function(){return i}});let i=t.p+"assets/images/excel-23850449d4d74099a1264cd93ca8565b.webp"},37272:function(e,n,t){t.d(n,{Z:function(){return i}});let i=t.p+"assets/images/form-774ee8d03c87acfc38d3012d38a9c4ce.webp"},5571:function(e,n,t){t.d(n,{Z:function(){return i}});let i=t.p+"assets/images/inspect-90f77b162804bd1163b16bb23b315ed8.webp"},97341:function(e,n,t){t.d(n,{Z:function(){return i}});let i=t.p+"assets/images/linkedin-homepage-8bec2b6a9ae97a18a7e49d4275c14cee.webp"},27388:function(e,n,t){t.d(n,{Z:function(){return i}});let i="data:image/webp;base64,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"},18393:function(e,n,t){t.d(n,{Z:function(){return i}});let i=t.p+"assets/images/linkedin-jobs-44e352d2233de5adb7af9838b75b9895.webp"},254:function(e,n,t){t.d(n,{Z:function(){return i}});let i=t.p+"assets/images/running-555ab15f009be751f516aabd99e6c574.webp"},50065:function(e,n,t){t.d(n,{Z:function(){return s},a:function(){return o}});var i=t(67294);let r={},a=i.createContext(r);function o(e){let n=i.useContext(a);return i.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function s(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:o(e.components),i.createElement(a.Provider,{value:n},e.children)}},14883:function(e){e.exports=JSON.parse('{"permalink":"/blog/linkedin-job-scraper-python","source":"@site/blog/2024/10-14-linkedin-job-scraper-python/index.md","title":"How to create a LinkedIn job scraper in Python with Crawlee","description":"Learn how to scrape LinkedIn jobs and save it into a CSV file using Python.","date":"2024-10-14T00:00:00.000Z","tags":[],"readingTime":6.265,"hasTruncateMarker":true,"authors":[{"name":"Arindam Majumder","title":"Community Member of Crawlee","url":"https://github.com/Arindam200","socials":{"x":"https://x.com/Arindam_1729","github":"https://github.com/Arindam200"},"imageURL":"https://avatars.githubusercontent.com/u/109217591?v=4","key":"ArindamM","page":null}],"frontMatter":{"slug":"linkedin-job-scraper-python","title":"How to create a LinkedIn job scraper in Python with Crawlee","description":"Learn how to scrape LinkedIn jobs and save it into a CSV file using Python.","image":"./img/linkedin-job-scraper.webp","authors":["ArindamM"]},"unlisted":false,"prevItem":{"title":"12 tips on how to think like a web scraping expert","permalink":"/blog/web-scraping-tips"},"nextItem":{"title":"Optimizing web scraping: Scraping auth data using JSDOM","permalink":"/blog/scrape-using-jsdom"}}')}}]);