"use strict";(self.webpackChunk=self.webpackChunk||[]).push([["3207"],{12511:function(e,n,r){r.r(n),r.d(n,{assets:function(){return l},contentTitle:function(){return s},default:function(){return d},frontMatter:function(){return o},metadata:function(){return t},toc:function(){return h}});var t=r(75039),a=r(85893),i=r(50065);let o={slug:"launching-crawlee-python",title:"Announcing Crawlee for Python: Now you can use Python to build reliable web crawlers",description:"Launching Crawlee for Python, a web scraping and automation library to build reliable scrapers in Python fastly.",image:"./img/crawlee-python.webp",authors:["SauravJ"]},s=void 0,l={image:r(37517).Z,authorsImageUrls:[void 0]},h=[{value:"Why use Crawlee instead of a random HTTP library with an HTML parser?",id:"why-use-crawlee-instead-of-a-random-http-library-with-an-html-parser",level:2},{value:"Understanding the why behind the features of Crawlee",id:"understanding-the-why-behind-the-features-of-crawlee",level:2},{value:"Out-of-the-box support for headless browser crawling (Playwright).",id:"out-of-the-box-support-for-headless-browser-crawling-playwright",level:3},{value:"Small learning curve",id:"small-learning-curve",level:3},{value:"Complete type hint coverage",id:"complete-type-hint-coverage",level:3},{value:"Based on Asyncio",id:"based-on-asyncio",level:3},{value:"Power of open source community and early adopters giveaway",id:"power-of-open-source-community-and-early-adopters-giveaway",level:2}];function c(e){let n={a:"a",blockquote:"blockquote",code:"code",h2:"h2",h3:"h3",img:"img",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,i.a)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsxs)(n.blockquote,{children:["\n",(0,a.jsx)(n.p,{children:"Testimonial from early adopters"}),"\n",(0,a.jsx)(n.p,{children:"\u201CCrawlee for Python development team did a great job in building the product, it makes things faster for a Python developer.\u201D"}),"\n",(0,a.jsxs)(n.p,{children:["~ ",(0,a.jsx)(n.a,{href:"https://apify.com/mantisus",children:"Maksym Bohomolov"})]}),"\n"]}),"\n",(0,a.jsxs)(n.p,{children:["We launched Crawlee in ",(0,a.jsx)(n.a,{href:"https://blog.apify.com/announcing-crawlee-the-web-scraping-and-browser-automation-library/",children:"August 2022"})," and got an amazing response from the JavaScript community. With many early adopters in its initial days, we got valuable feedback, which gave Crawlee a strong base for its success."]}),"\n",(0,a.jsxs)(n.p,{children:["Today, ",(0,a.jsx)(n.a,{href:"https://github.com/apify/crawlee",children:"Crawlee built-in TypeScript"})," has nearly ",(0,a.jsx)(n.strong,{children:"13,000 stars on GitHub"}),", with 90 open-source contributors worldwide building the best web scraping and automation library."]}),"\n",(0,a.jsxs)(n.p,{children:["Since the launch, the feedback we\u2019ve received most often ",(0,a.jsx)(n.a,{href:"https://discord.com/channels/801163717915574323/999250964554981446/1138826582581059585",children:"[1]"}),(0,a.jsx)(n.a,{href:"https://discord.com/channels/801163717915574323/801163719198638092/1137702376267059290",children:"[2]"}),(0,a.jsx)(n.a,{href:"https://discord.com/channels/801163717915574323/1090592836044476426/1103977818221719584",children:"[3]"})," has been to build Crawlee in Python so that the Python community can use all the features the JavaScript community does."]}),"\n",(0,a.jsxs)(n.p,{children:["With all these requests in mind and to simplify the life of Python web scraping developers, ",(0,a.jsxs)(n.strong,{children:["we\u2019re launching ",(0,a.jsx)(n.a,{href:"https://github.com/apify/crawlee-python",children:"Crawlee for Python"})," today."]})]}),"\n",(0,a.jsxs)(n.p,{children:["The new library is still in ",(0,a.jsx)(n.strong,{children:"beta"}),", and we are looking for ",(0,a.jsx)(n.strong,{children:"early adopters"}),"."]}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.img,{alt:"Crawlee for Python is looking for early adopters",src:r(26101).Z+"",width:"1920",height:"1080"})}),"\n",(0,a.jsx)(n.p,{children:"Crawlee for Python has some amazing initial features, such as a unified interface for HTTP and headless browser crawling, automatic retries, and much more."}),"\n",(0,a.jsx)(n.h2,{id:"why-use-crawlee-instead-of-a-random-http-library-with-an-html-parser",children:"Why use Crawlee instead of a random HTTP library with an HTML parser?"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["Unified interface for HTTP & headless browser crawling.","\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"HTTP - HTTPX with BeautifulSoup,"}),"\n",(0,a.jsx)(n.li,{children:"Headless browser - Playwright."}),"\n"]}),"\n"]}),"\n",(0,a.jsx)(n.li,{children:"Automatic parallel crawling based on available system resources."}),"\n",(0,a.jsx)(n.li,{children:"Written in Python with type hints - enhances DX (IDE autocompletion) and reduces bugs (static type checking)."}),"\n",(0,a.jsx)(n.li,{children:"Automatic retries on errors or when you\u2019re getting blocked."}),"\n",(0,a.jsx)(n.li,{children:"Integrated proxy rotation and session management."}),"\n",(0,a.jsx)(n.li,{children:"Configurable request routing - direct URLs to the appropriate handlers."}),"\n",(0,a.jsx)(n.li,{children:"Persistent queue for URLs to crawl."}),"\n",(0,a.jsx)(n.li,{children:"Pluggable storage of both tabular data and files."}),"\n"]}),"\n",(0,a.jsx)(n.h2,{id:"understanding-the-why-behind-the-features-of-crawlee",children:"Understanding the why behind the features of Crawlee"}),"\n",(0,a.jsx)(n.h3,{id:"out-of-the-box-support-for-headless-browser-crawling-playwright",children:"Out-of-the-box support for headless browser crawling (Playwright)."}),"\n",(0,a.jsxs)(n.p,{children:["While libraries like Scrapy require additional installation of middleware, i.e, ",(0,a.jsx)(n.a,{href:"https://github.com/scrapy-plugins/scrapy-playwright",children:(0,a.jsx)(n.code,{children:"scrapy-playwright"})})," and still doesn\u2019t work with Windows, Crawlee for Python supports a unified interface for HTTP & headless browsers."]}),"\n",(0,a.jsxs)(n.p,{children:["Using a headless browser to download web pages and extract data, ",(0,a.jsx)(n.code,{children:"PlaywrightCrawler"})," is ideal for crawling websites that require JavaScript execution."]}),"\n",(0,a.jsxs)(n.p,{children:["For websites that don\u2019t require JavaScript, consider using the ",(0,a.jsx)(n.code,{children:"BeautifulSoupCrawler,"})," which utilizes raw HTTP requests and will be much faster."]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"import asyncio\n\nfrom crawlee.playwright_crawler import PlaywrightCrawler, PlaywrightCrawlingContext\n\n\nasync def main() -> None:\n    # Create a crawler instance\n    crawler = PlaywrightCrawler(\n        # headless=False,\n        # browser_type='firefox',\n    )\n\n    @crawler.router.default_handler\n    async def request_handler(context: PlaywrightCrawlingContext) -> None:\n        data = {\n            'request_url': context.request.url,\n            'page_url': context.page.url,\n            'page_title': await context.page.title(),\n            'page_content': (await context.page.content())[:10000],\n        }\n        await context.push_data(data)\n\n    await crawler.run(['https://crawlee.dev'])\n\n\nif __name__ == '__main__':\n    asyncio.run(main())\n"})}),"\n",(0,a.jsxs)(n.p,{children:["The above example uses Crawlee\u2019s built-in ",(0,a.jsx)(n.code,{children:"PlaywrightCrawler"})," to crawl the ",(0,a.jsx)(n.a,{href:"https://crawlee.dev/",children:"https://crawlee.dev/"})," website title and its content."]}),"\n",(0,a.jsx)(n.h3,{id:"small-learning-curve",children:"Small learning curve"}),"\n",(0,a.jsxs)(n.p,{children:["In other libraries like Scrapy, when you run a command to create a new project, you get many files. Then you need to learn about the architecture, including various components (spiders, middlewares, pipelines, etc.). ",(0,a.jsx)(n.a,{href:"https://crawlee.dev/blog/scrapy-vs-crawlee#language-and-development-environments",children:"The learning curve is very steep"}),"."]}),"\n",(0,a.jsx)(n.p,{children:"While building Crawlee, we made sure that the learning curve and the setup would be as fast as possible."}),"\n",(0,a.jsxs)(n.p,{children:["With ",(0,a.jsx)(n.a,{href:"https://github.com/apify/crawlee-python/tree/master/templates",children:"ready-made templates"}),", and having only a single file to add the code, it's very easy to start building a scraper, you might need to learn a little about request handlers and storage, but that\u2019s all."]}),"\n",(0,a.jsx)(n.h3,{id:"complete-type-hint-coverage",children:"Complete type hint coverage"}),"\n",(0,a.jsx)(n.p,{children:"We know how much developers like their code to be high-quality, readable, and maintainable."}),"\n",(0,a.jsx)(n.p,{children:"That's why the whole code base of Crawlee is fully type-hinted."}),"\n",(0,a.jsx)(n.p,{children:"Thanks to that, you should have better autocompletion in your IDE, enhancing developer experience while developing your scrapers using Crawlee."}),"\n",(0,a.jsx)(n.p,{children:"Type hinting should also reduce the number of bugs thanks to static type checking."}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.img,{alt:"Crawlee_Python_Type_Hint",src:r(30676).Z+"",width:"877",height:"457"})}),"\n",(0,a.jsx)(n.h3,{id:"based-on-asyncio",children:"Based on Asyncio"}),"\n",(0,a.jsxs)(n.p,{children:["Crawlee is fully asynchronous and based on ",(0,a.jsx)(n.a,{href:"https://docs.python.org/3/library/asyncio.html",children:"Asyncio"}),". For scraping frameworks, where many IO-bounds operations occur, this should be crucial to achieving high performance."]}),"\n",(0,a.jsx)(n.p,{children:"Also, thanks to Asyncio, integration with other applications or the rest of your system should be easy."}),"\n",(0,a.jsx)(n.p,{children:"How is this different from the Scrapy framework, which is also asynchronous?"}),"\n",(0,a.jsxs)(n.p,{children:['Scrapy relies on the "legacy" Twisted framework. Integrating Scrapy with modern Asyncio-based applications can be challenging, often requiring more effort and debugging ',(0,a.jsx)(n.a,{href:"https://stackoverflow.com/questions/49201915/debugging-scrapy-project-in-visual-studio-code",children:"[1]"}),"."]}),"\n",(0,a.jsx)(n.h2,{id:"power-of-open-source-community-and-early-adopters-giveaway",children:"Power of open source community and early adopters giveaway"}),"\n",(0,a.jsxs)(n.p,{children:["Crawlee for Python is fully open-sourced and the codebase is available on the ",(0,a.jsx)(n.a,{href:"https://github.com/apify/crawlee-python",children:"GitHub repository of Crawlee for Python"}),"."]}),"\n",(0,a.jsxs)(n.p,{children:["We have already started receiving initial and very ",(0,a.jsx)(n.a,{href:"https://github.com/apify/crawlee-python/pull/226",children:"valuable contributions from the Python community"}),"."]}),"\n",(0,a.jsxs)(n.blockquote,{children:["\n",(0,a.jsx)(n.p,{children:"Early adopters also said:"}),"\n",(0,a.jsx)(n.p,{children:"\u201CCrawlee for Python development team did a great job in building the product, it makes things faster for a Python developer.\u201D"}),"\n",(0,a.jsxs)(n.p,{children:["~ ",(0,a.jsx)(n.a,{href:"https://apify.com/mantisus",children:"Maksym Bohomolov"})]}),"\n"]}),"\n",(0,a.jsxs)(n.p,{children:["There\u2019s still room for improvement. Feel free to open issues, make pull requests, and ",(0,a.jsx)(n.a,{href:"https://github.com/apify/crawlee-python/",children:"star the repository"})," to spread the work to other developers."]}),"\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"We will award the first 10 pieces of feedback"})," that add value and are accepted by our team with an exclusive Crawlee for Python swag (The first Crawlee for Python swag ever). Check out the ",(0,a.jsx)(n.a,{href:"https://github.com/apify/crawlee-python/issues/269/",children:"GitHub issue here"}),"."]}),"\n",(0,a.jsx)(n.p,{children:"With such contributions, we\u2019re excited and looking forward to building an amazing library for the Python community."}),"\n",(0,a.jsxs)(n.p,{children:["Check out a step by step guide on how to use Crawlee for Python through one of our ",(0,a.jsx)(n.a,{href:"https://blog.apify.com/crawlee-for-python-tutorial/",children:"latest tutorial"}),"."]}),"\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.a,{href:"https://apify.com/discord",children:"Join our Discord community"})," with nearly 8,000 web scraping developers, where our team would be happy to help you with any problems or discuss any use case for Crawlee for Python."]})]})}function d(e={}){let{wrapper:n}={...(0,i.a)(),...e.components};return n?(0,a.jsx)(n,{...e,children:(0,a.jsx)(c,{...e})}):c(e)}},37517:function(e,n,r){r.d(n,{Z:function(){return t}});let t=r.p+"assets/images/crawlee-python-22cfa15f07f79ee6bd5713c3fc45de18.webp"},30676:function(e,n,r){r.d(n,{Z:function(){return t}});let t=r.p+"assets/images/crawlee-python-type-hint-90bb0ec4fb86916d8a6b2512a80f965b.webp"},26101:function(e,n,r){r.d(n,{Z:function(){return t}});let t=r.p+"assets/images/early-adopters-0c5f38327dd8e5fad85dc127dcabc1f0.webp"},50065:function(e,n,r){r.d(n,{Z:function(){return s},a:function(){return o}});var t=r(67294);let a={},i=t.createContext(a);function o(e){let n=t.useContext(i);return t.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function s(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:o(e.components),t.createElement(i.Provider,{value:n},e.children)}},75039:function(e){e.exports=JSON.parse('{"permalink":"/blog/launching-crawlee-python","source":"@site/blog/2024/07-05-launching-crawlee-python/index.md","title":"Announcing Crawlee for Python: Now you can use Python to build reliable web crawlers","description":"Launching Crawlee for Python, a web scraping and automation library to build reliable scrapers in Python fastly.","date":"2024-07-05T00:00:00.000Z","tags":[],"readingTime":4.545,"hasTruncateMarker":true,"authors":[{"name":"Saurav Jain","title":"Developer Community Manager","url":"https://github.com/souravjain540","socials":{"x":"https://x.com/sauain","github":"https://github.com/souravjain540"},"imageURL":"https://avatars.githubusercontent.com/u/53312820?v=4","key":"SauravJ","page":null}],"frontMatter":{"slug":"launching-crawlee-python","title":"Announcing Crawlee for Python: Now you can use Python to build reliable web crawlers","description":"Launching Crawlee for Python, a web scraping and automation library to build reliable scrapers in Python fastly.","image":"./img/crawlee-python.webp","authors":["SauravJ"]},"unlisted":false,"prevItem":{"title":"Current problems and mistakes of web scraping in Python and tricks to solve them!","permalink":"/blog/common-problems-in-web-scraping"},"nextItem":{"title":"How Crawlee uses tiered proxies to avoid getting blocked","permalink":"/blog/proxy-management-in-crawlee"}}')}}]);