"use strict";(self.webpackChunk=self.webpackChunk||[]).push([["91500"],{17668:function(e,n,r){r.r(n),r.d(n,{default:()=>w,frontMatter:()=>u,metadata:()=>o,assets:()=>d,toc:()=>h,contentTitle:()=>p});var o=JSON.parse('{"id":"guides/proxy-management","title":"Proxy Management","description":"Using proxies to get around those annoying IP-blocks","source":"@site/../docs/guides/proxy_management.mdx","sourceDirName":"guides","slug":"/guides/proxy-management","permalink":"/docs/next/guides/proxy-management","draft":false,"unlisted":false,"editUrl":"https://github.com/apify/crawlee/edit/master/website/../docs/guides/proxy_management.mdx","tags":[],"version":"current","lastUpdatedBy":"Jind\u0159ich B\xe4r","lastUpdatedAt":1737128153000,"frontMatter":{"id":"proxy-management","title":"Proxy Management","description":"Using proxies to get around those annoying IP-blocks"},"sidebar":"docs","previous":{"title":"JavaScript rendering","permalink":"/docs/next/guides/javascript-rendering"},"next":{"title":"Session Management","permalink":"/docs/next/guides/session-management"}}'),t=r("85893"),i=r("50065"),a=r("47927"),s=r("58168"),l=r("97645"),c=r("96199");let u={id:"proxy-management",title:"Proxy Management",description:"Using proxies to get around those annoying IP-blocks"},p=void 0,d={},h=[{value:"Quick start",id:"quick-start",level:2},{value:"Proxy Configuration",id:"proxy-configuration",level:2},{value:"Static proxy list",id:"static-proxy-list",level:3},{value:"Custom proxy function",id:"custom-proxy-function",level:3},{value:"Tiered proxies",id:"tiered-proxies",level:3},{value:"Crawler integration",id:"crawler-integration",level:2},{value:"IP Rotation and session management",id:"ip-rotation-and-session-management",level:2},{value:"Inspecting current proxy in Crawlers",id:"inspecting-current-proxy-in-crawlers",level:2}];function x(e){let n={a:"a",admonition:"admonition",code:"code",h2:"h2",h3:"h3",p:"p",pre:"pre",...(0,i.a)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.a,{href:"https://en.wikipedia.org/wiki/IP_address_blocking",target:"_blank",rel:"noopener",children:"IP address blocking"})," is one of the oldest\nand most effective ways of preventing access to a website. It is therefore paramount for\na good web scraping library to provide easy to use but powerful tools which can work around\nIP blocking. The most powerful weapon in our anti IP blocking arsenal is a\n",(0,t.jsx)(n.a,{href:"https://en.wikipedia.org/wiki/Proxy_server",target:"_blank",rel:"noopener",children:"proxy server"}),"."]}),"\n",(0,t.jsx)(n.p,{children:"With Crawlee we can use our own proxy servers or proxy servers acquired from\nthird-party providers."}),"\n",(0,t.jsxs)(n.p,{children:["Check out the ",(0,t.jsx)(n.a,{href:"./avoid-blocking",children:"avoid blocking guide"})," for more information about blocking."]}),"\n",(0,t.jsx)(n.h2,{id:"quick-start",children:"Quick start"}),"\n",(0,t.jsx)(n.p,{children:"If we already have proxy URLs of our own, we can start using\nthem immediately in only a few lines of code."}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-javascript",children:"import { ProxyConfiguration } from 'crawlee';\n\nconst proxyConfiguration = new ProxyConfiguration({\n    proxyUrls: [\n        'http://proxy-1.com',\n        'http://proxy-2.com',\n    ]\n});\nconst proxyUrl = await proxyConfiguration.newUrl();\n"})}),"\n",(0,t.jsxs)(n.p,{children:["Examples of how to use our proxy URLs with crawlers are shown below in ",(0,t.jsx)(n.a,{href:"#crawler-integration",children:"Crawler integration"})," section."]}),"\n",(0,t.jsx)(n.h2,{id:"proxy-configuration",children:"Proxy Configuration"}),"\n",(0,t.jsxs)(n.p,{children:["All our proxy needs are managed by the ",(0,t.jsx)(a.Z,{to:"core/class/ProxyConfiguration",children:(0,t.jsx)(n.code,{children:"ProxyConfiguration"})})," class. We create an instance using the ",(0,t.jsx)(n.code,{children:"ProxyConfiguration"})," ",(0,t.jsx)(a.Z,{to:"core/class/ProxyConfiguration#constructor",children:(0,t.jsx)(n.code,{children:"constructor"})})," function based on the provided options. See the ",(0,t.jsx)(a.Z,{to:"core/interface/ProxyConfigurationOptions",children:(0,t.jsx)(n.code,{children:"ProxyConfigurationOptions"})})," for all the possible constructor options."]}),"\n",(0,t.jsx)(n.h3,{id:"static-proxy-list",children:"Static proxy list"}),"\n",(0,t.jsxs)(n.p,{children:["You can provide a static list of proxy URLs to the ",(0,t.jsx)(n.code,{children:"proxyUrls"})," option. The ",(0,t.jsx)(n.code,{children:"ProxyConfiguration"})," will then rotate through the provided proxies."]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-javascript",children:"const proxyConfiguration = new ProxyConfiguration({\n    proxyUrls: [\n        'http://proxy-1.com',\n        'http://proxy-2.com',\n        null // null means no proxy is used\n    ]\n});\n"})}),"\n",(0,t.jsx)(n.p,{children:"This is the simplest way to use a list of proxies. Crawlee will rotate through the list of proxies in a round-robin fashion."}),"\n",(0,t.jsx)(n.h3,{id:"custom-proxy-function",children:"Custom proxy function"}),"\n",(0,t.jsxs)(n.p,{children:["The ",(0,t.jsx)(n.code,{children:"ProxyConfiguration"})," class allows you to provide a custom function to pick a proxy URL. This is useful when you want to implement your own logic for selecting a proxy."]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-javascript",children:"const proxyConfiguration = new ProxyConfiguration({\n    newUrlFunction: (sessionId, { request }) => {\n        if (request?.url.includes('crawlee.dev')) {\n            return null; // for crawlee.dev, we don't use a proxy\n        }\n\n        return 'http://proxy-1.com'; // for all other URLs, we use this proxy\n    }\n});\n"})}),"\n",(0,t.jsxs)(n.p,{children:["The ",(0,t.jsx)(n.code,{children:"newUrlFunction"})," receives two parameters - ",(0,t.jsx)(n.code,{children:"sessionId"})," and ",(0,t.jsx)(n.code,{children:"options"})," - and returns a string containing the proxy URL."]}),"\n",(0,t.jsxs)(n.p,{children:["The ",(0,t.jsx)(n.code,{children:"sessionId"})," parameter is always provided and allows us to differentiate between different sessions - e.g. when Crawlee recognizes your crawlers are being blocked, it will automatically create a new session with a different id."]}),"\n",(0,t.jsxs)(n.p,{children:["The ",(0,t.jsx)(n.code,{children:"options"})," parameter is an object containing a ",(0,t.jsx)(a.Z,{to:"core/class/Request",children:(0,t.jsx)(n.code,{children:"Request"})}),", which is the request that will be made. Note that this object is not always available, for example when we are using the ",(0,t.jsx)(n.code,{children:"newUrl"})," function directly. Your custom function should therefore not rely on the ",(0,t.jsx)(n.code,{children:"request"})," object being present and provide a default behavior when it is not."]}),"\n",(0,t.jsx)(n.h3,{id:"tiered-proxies",children:"Tiered proxies"}),"\n",(0,t.jsxs)(n.p,{children:["You can also provide a list of proxy tiers to the ",(0,t.jsx)(n.code,{children:"ProxyConfiguration"})," class. This is useful when you want to switch between different proxies automatically based on the blocking behavior of the website."]}),"\n",(0,t.jsxs)(n.admonition,{type:"warning",children:[(0,t.jsxs)(n.p,{children:["Note that the ",(0,t.jsx)(n.code,{children:"tieredProxyUrls"})," option requires ",(0,t.jsx)(n.code,{children:"ProxyConfiguration"})," to be used from a crawler instance (",(0,t.jsx)(n.a,{href:"#crawler-integration",children:"see below"}),")."]}),(0,t.jsxs)(n.p,{children:["Using this configuration through the ",(0,t.jsx)(n.code,{children:"newUrl"})," calls will not yield the expected results."]})]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-javascript",children:"const proxyConfiguration = new ProxyConfiguration({\n    tieredProxyUrls: [\n        [null], // At first, we try to connect without a proxy\n        ['http://okay-proxy.com'],\n        ['http://slightly-better-proxy.com', 'http://slightly-better-proxy-2.com'],\n        ['http://very-good-and-expensive-proxy.com'],\n    ]\n});\n"})}),"\n",(0,t.jsxs)(n.p,{children:["This configuration will start with no proxy, then switch to ",(0,t.jsx)(n.code,{children:"http://okay-proxy.com"})," if Crawlee recognizes we're getting blocked by the target website. If that proxy is also blocked, we will switch to one of the ",(0,t.jsx)(n.code,{children:"slightly-better-proxy"})," URLs. If those are blocked, we will switch to the ",(0,t.jsx)(n.code,{children:"very-good-and-expensive-proxy.com"})," URL."]}),"\n",(0,t.jsx)(n.p,{children:"Crawlee also periodically probes lower tier proxies to see if they are unblocked, and if they are, it will switch back to them."}),"\n",(0,t.jsx)(n.h2,{id:"crawler-integration",children:"Crawler integration"}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.code,{children:"ProxyConfiguration"})," integrates seamlessly into ",(0,t.jsx)(a.Z,{to:"http-crawler/class/HttpCrawler",children:(0,t.jsx)(n.code,{children:"HttpCrawler"})}),", ",(0,t.jsx)(a.Z,{to:"cheerio-crawler/class/CheerioCrawler",children:(0,t.jsx)(n.code,{children:"CheerioCrawler"})}),", ",(0,t.jsx)(a.Z,{to:"jsdom-crawler/class/JSDOMCrawler",children:(0,t.jsx)(n.code,{children:"JSDOMCrawler"})}),", ",(0,t.jsx)(a.Z,{to:"playwright-crawler/class/PlaywrightCrawler",children:(0,t.jsx)(n.code,{children:"PlaywrightCrawler"})})," and ",(0,t.jsx)(a.Z,{to:"puppeteer-crawler/class/PuppeteerCrawler",children:(0,t.jsx)(n.code,{children:"PuppeteerCrawler"})}),"."]}),"\n",(0,t.jsxs)(s.Z,{groupId:"proxy_session_management",children:[(0,t.jsx)(l.Z,{value:"http",label:"HttpCrawler",children:(0,t.jsx)(c.default,{language:"js",children:"import { HttpCrawler, ProxyConfiguration } from 'crawlee';\n\nconst proxyConfiguration = new ProxyConfiguration({\n    proxyUrls: ['http://proxy-1.com', 'http://proxy-2.com'],\n});\n\nconst crawler = new HttpCrawler({\n    proxyConfiguration,\n    // ...\n});\n"})}),(0,t.jsx)(l.Z,{value:"cheerio",label:"CheerioCrawler",default:!0,children:(0,t.jsx)(c.default,{language:"js",children:"import { CheerioCrawler, ProxyConfiguration } from 'crawlee';\n\nconst proxyConfiguration = new ProxyConfiguration({\n    proxyUrls: ['http://proxy-1.com', 'http://proxy-2.com'],\n});\n\nconst crawler = new CheerioCrawler({\n    proxyConfiguration,\n    // ...\n});\n"})}),(0,t.jsx)(l.Z,{value:"jsdom",label:"JSDOMCrawler",children:(0,t.jsx)(c.default,{language:"js",children:"import { JSDOMCrawler, ProxyConfiguration } from 'crawlee';\n\nconst proxyConfiguration = new ProxyConfiguration({\n    proxyUrls: ['http://proxy-1.com', 'http://proxy-2.com'],\n});\n\nconst crawler = new JSDOMCrawler({\n    proxyConfiguration,\n    // ...\n});\n"})}),(0,t.jsx)(l.Z,{value:"playwright",label:"PlaywrightCrawler",children:(0,t.jsx)(c.default,{language:"js",children:"import { PlaywrightCrawler, ProxyConfiguration } from 'crawlee';\n\nconst proxyConfiguration = new ProxyConfiguration({\n    proxyUrls: ['http://proxy-1.com', 'http://proxy-2.com'],\n});\n\nconst crawler = new PlaywrightCrawler({\n    proxyConfiguration,\n    // ...\n});\n"})}),(0,t.jsx)(l.Z,{value:"puppeteer",label:"PuppeteerCrawler",children:(0,t.jsx)(c.default,{language:"js",children:"import { PuppeteerCrawler, ProxyConfiguration } from 'crawlee';\n\nconst proxyConfiguration = new ProxyConfiguration({\n    proxyUrls: ['http://proxy-1.com', 'http://proxy-2.com'],\n});\n\nconst crawler = new PuppeteerCrawler({\n    proxyConfiguration,\n    // ...\n});\n"})})]}),"\n",(0,t.jsx)(n.p,{children:"Our crawlers will now use the selected proxies for all connections."}),"\n",(0,t.jsx)(n.h2,{id:"ip-rotation-and-session-management",children:"IP Rotation and session management"}),"\n",(0,t.jsxs)(n.p,{children:["\u200B",(0,t.jsx)(a.Z,{to:"core/class/ProxyConfiguration#newUrl",children:(0,t.jsx)(n.code,{children:"proxyConfiguration.newUrl()"})})," allows us to pass a ",(0,t.jsx)(n.code,{children:"sessionId"})," parameter. It will then be used to create a ",(0,t.jsx)(n.code,{children:"sessionId"}),"-",(0,t.jsx)(n.code,{children:"proxyUrl"})," pair, and subsequent ",(0,t.jsx)(n.code,{children:"newUrl()"})," calls with the same ",(0,t.jsx)(n.code,{children:"sessionId"})," will always return the same ",(0,t.jsx)(n.code,{children:"proxyUrl"}),". This is extremely useful in scraping, because we want to create the impression of a real user. See the ",(0,t.jsx)(n.a,{href:"../guides/session-management",children:"session management guide"})," and ",(0,t.jsx)(a.Z,{to:"core/class/SessionPool",children:(0,t.jsx)(n.code,{children:"SessionPool"})})," class for more information on how keeping a real session helps us avoid blocking."]}),"\n",(0,t.jsxs)(n.p,{children:["When no ",(0,t.jsx)(n.code,{children:"sessionId"})," is provided, our proxy URLs are rotated round-robin."]}),"\n",(0,t.jsxs)(s.Z,{groupId:"proxy_session_management",children:[(0,t.jsx)(l.Z,{value:"http",label:"HttpCrawler",children:(0,t.jsx)(c.default,{language:"js",children:"import { HttpCrawler, ProxyConfiguration } from 'crawlee';\n\nconst proxyConfiguration = new ProxyConfiguration({\n    /* opts */\n});\n\nconst crawler = new HttpCrawler({\n    useSessionPool: true,\n    persistCookiesPerSession: true,\n    proxyConfiguration,\n    // ...\n});\n"})}),(0,t.jsx)(l.Z,{value:"cheerio",label:"CheerioCrawler",default:!0,children:(0,t.jsx)(c.default,{language:"js",children:"import { CheerioCrawler, ProxyConfiguration } from 'crawlee';\n\nconst proxyConfiguration = new ProxyConfiguration({\n    /* opts */\n});\n\nconst crawler = new CheerioCrawler({\n    useSessionPool: true,\n    persistCookiesPerSession: true,\n    proxyConfiguration,\n    // ...\n});\n"})}),(0,t.jsx)(l.Z,{value:"jsdom",label:"JSDOMCrawler",children:(0,t.jsx)(c.default,{language:"js",children:"import { JSDOMCrawler, ProxyConfiguration } from 'crawlee';\n\nconst proxyConfiguration = new ProxyConfiguration({\n    /* opts */\n});\n\nconst crawler = new JSDOMCrawler({\n    useSessionPool: true,\n    persistCookiesPerSession: true,\n    proxyConfiguration,\n    // ...\n});\n"})}),(0,t.jsx)(l.Z,{value:"playwright",label:"PlaywrightCrawler",children:(0,t.jsx)(c.default,{language:"js",children:"import { PlaywrightCrawler, ProxyConfiguration } from 'crawlee';\n\nconst proxyConfiguration = new ProxyConfiguration({\n    /* opts */\n});\n\nconst crawler = new PlaywrightCrawler({\n    useSessionPool: true,\n    persistCookiesPerSession: true,\n    proxyConfiguration,\n    // ...\n});\n"})}),(0,t.jsx)(l.Z,{value:"puppeteer",label:"PuppeteerCrawler",children:(0,t.jsx)(c.default,{language:"js",children:"import { PuppeteerCrawler, ProxyConfiguration } from 'crawlee';\n\nconst proxyConfiguration = new ProxyConfiguration({\n    /* opts */\n});\n\nconst crawler = new PuppeteerCrawler({\n    useSessionPool: true,\n    persistCookiesPerSession: true,\n    proxyConfiguration,\n    // ...\n});\n"})}),(0,t.jsx)(l.Z,{value:"standalone",label:"Standalone",children:(0,t.jsx)(c.default,{language:"js",children:"import { ProxyConfiguration, SessionPool } from 'crawlee';\n\nconst proxyConfiguration = new ProxyConfiguration({\n    /* opts */\n});\n\nconst sessionPool = await SessionPool.open({\n    /* opts */\n});\n\nconst session = await sessionPool.getSession();\n\nconst proxyUrl = await proxyConfiguration.newUrl(session.id);\n"})})]}),"\n",(0,t.jsx)(n.h2,{id:"inspecting-current-proxy-in-crawlers",children:"Inspecting current proxy in Crawlers"}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.code,{children:"HttpCrawler"}),", ",(0,t.jsx)(n.code,{children:"CheerioCrawler"}),", ",(0,t.jsx)(n.code,{children:"JSDOMCrawler"}),", ",(0,t.jsx)(n.code,{children:"PlaywrightCrawler"})," and ",(0,t.jsx)(n.code,{children:"PuppeteerCrawler"})," grant access to information about the currently used proxy\nin their ",(0,t.jsx)(n.code,{children:"requestHandler"})," using a ",(0,t.jsx)(a.Z,{to:"core/interface/ProxyInfo",children:(0,t.jsx)(n.code,{children:"proxyInfo"})})," object.\nWith the ",(0,t.jsx)(n.code,{children:"proxyInfo"})," object, we can easily access the proxy URL."]}),"\n",(0,t.jsxs)(s.Z,{groupId:"proxy_session_management",children:[(0,t.jsx)(l.Z,{value:"http",label:"HttpCrawler",children:(0,t.jsx)(c.default,{language:"js",children:"import { HttpCrawler, ProxyConfiguration } from 'crawlee';\n\nconst proxyConfiguration = new ProxyConfiguration({\n    /* opts */\n});\n\nconst crawler = new HttpCrawler({\n    proxyConfiguration,\n    async requestHandler({ proxyInfo }) {\n        console.log(proxyInfo);\n    },\n    // ...\n});\n"})}),(0,t.jsx)(l.Z,{value:"cheerio",label:"CheerioCrawler",default:!0,children:(0,t.jsx)(c.default,{language:"js",children:"import { CheerioCrawler, ProxyConfiguration } from 'crawlee';\n\nconst proxyConfiguration = new ProxyConfiguration({\n    /* opts */\n});\n\nconst crawler = new CheerioCrawler({\n    proxyConfiguration,\n    async requestHandler({ proxyInfo }) {\n        console.log(proxyInfo);\n    },\n    // ...\n});\n"})}),(0,t.jsx)(l.Z,{value:"jsdom",label:"JSDOMCrawler",children:(0,t.jsx)(c.default,{language:"js",children:"import { JSDOMCrawler, ProxyConfiguration } from 'crawlee';\n\nconst proxyConfiguration = new ProxyConfiguration({\n    /* opts */\n});\n\nconst crawler = new JSDOMCrawler({\n    proxyConfiguration,\n    async requestHandler({ proxyInfo }) {\n        console.log(proxyInfo);\n    },\n    // ...\n});\n"})}),(0,t.jsx)(l.Z,{value:"playwright",label:"PlaywrightCrawler",children:(0,t.jsx)(c.default,{language:"js",children:"import { PlaywrightCrawler, ProxyConfiguration } from 'crawlee';\n\nconst proxyConfiguration = new ProxyConfiguration({\n    /* opts */\n});\n\nconst crawler = new PlaywrightCrawler({\n    proxyConfiguration,\n    async requestHandler({ proxyInfo }) {\n        console.log(proxyInfo);\n    },\n    // ...\n});\n"})}),(0,t.jsx)(l.Z,{value:"puppeteer",label:"PuppeteerCrawler",children:(0,t.jsx)(c.default,{language:"js",children:"import { PuppeteerCrawler, ProxyConfiguration } from 'crawlee';\n\nconst proxyConfiguration = new ProxyConfiguration({\n    /* opts */\n});\n\nconst crawler = new PuppeteerCrawler({\n    proxyConfiguration,\n    async requestHandler({ proxyInfo }) {\n        console.log(proxyInfo);\n    },\n    // ...\n});\n"})})]})]})}function w(e={}){let{wrapper:n}={...(0,i.a)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(x,{...e})}):x(e)}},97645:function(e,n,r){r.d(n,{Z:()=>i});var o=r("85893");r("67294");var t=r("67026");function i(e){let{children:n,hidden:r,className:i}=e;return(0,o.jsx)("div",{role:"tabpanel",className:(0,t.Z)("tabItem_Ymn6",i),hidden:r,children:n})}},58168:function(e,n,r){r.d(n,{Z:()=>y});var o=r("85893"),t=r("67294"),i=r("67026"),a=r("34718"),s=r("16550"),l=r("8714"),c=r("89207"),u=r("69413"),p=r("54510");function d(e){return t.Children.toArray(e).filter(e=>"\n"!==e).map(e=>{if(!e||t.isValidElement(e)&&function(e){let{props:n}=e;return!!n&&"object"==typeof n&&"value"in n}(e))return e;throw Error(`Docusaurus error: Bad <Tabs> child <${"string"==typeof e.type?e.type:e.type.name}>: all children of the <Tabs> component should be <TabItem>, and every <TabItem> should have a unique "value" prop.`)})?.filter(Boolean)??[]}function h(e){let{value:n,tabValues:r}=e;return r.some(e=>e.value===n)}var x=r("6735");function w(e){let{className:n,block:r,selectedValue:t,selectValue:s,tabValues:l}=e,c=[],{blockElementScrollPositionUntilNextRender:u}=(0,a.o5)(),p=e=>{let n=e.currentTarget,r=l[c.indexOf(n)].value;r!==t&&(u(n),s(r))},d=e=>{let n=null;switch(e.key){case"Enter":p(e);break;case"ArrowRight":{let r=c.indexOf(e.currentTarget)+1;n=c[r]??c[0];break}case"ArrowLeft":{let r=c.indexOf(e.currentTarget)-1;n=c[r]??c[c.length-1]}}n?.focus()};return(0,o.jsx)("ul",{role:"tablist","aria-orientation":"horizontal",className:(0,i.Z)("tabs",{"tabs--block":r},n),children:l.map(e=>{let{value:n,label:r,attributes:a}=e;return(0,o.jsx)("li",{role:"tab",tabIndex:t===n?0:-1,"aria-selected":t===n,ref:e=>{c.push(e)},onKeyDown:d,onClick:p,...a,className:(0,i.Z)("tabs__item","tabItem_LNqP",a?.className,{"tabs__item--active":t===n}),children:r??n},n)})})}function f(e){let{lazy:n,children:r,selectedValue:a}=e,s=(Array.isArray(r)?r:[r]).filter(Boolean);if(n){let e=s.find(e=>e.props.value===a);return e?(0,t.cloneElement)(e,{className:(0,i.Z)("margin-top--md",e.props.className)}):null}return(0,o.jsx)("div",{className:"margin-top--md",children:s.map((e,n)=>(0,t.cloneElement)(e,{key:n,hidden:e.props.value!==a}))})}function g(e){let n=function(e){let{defaultValue:n,queryString:r=!1,groupId:o}=e,i=function(e){let{values:n,children:r}=e;return(0,t.useMemo)(()=>{let e=n??d(r).map(e=>{let{props:{value:n,label:r,attributes:o,default:t}}=e;return{value:n,label:r,attributes:o,default:t}});return!function(e){let n=(0,u.lx)(e,(e,n)=>e.value===n.value);if(n.length>0)throw Error(`Docusaurus error: Duplicate values "${n.map(e=>e.value).join(", ")}" found in <Tabs>. Every value needs to be unique.`)}(e),e},[n,r])}(e),[a,x]=(0,t.useState)(()=>(function(e){let{defaultValue:n,tabValues:r}=e;if(0===r.length)throw Error("Docusaurus error: the <Tabs> component requires at least one <TabItem> children component");if(n){if(!h({value:n,tabValues:r}))throw Error(`Docusaurus error: The <Tabs> has a defaultValue "${n}" but none of its children has the corresponding value. Available values are: ${r.map(e=>e.value).join(", ")}. If you intend to show no default tab, use defaultValue={null} instead.`);return n}let o=r.find(e=>e.default)??r[0];if(!o)throw Error("Unexpected error: 0 tabValues");return o.value})({defaultValue:n,tabValues:i})),[w,f]=function(e){let{queryString:n=!1,groupId:r}=e,o=(0,s.k6)(),i=function(e){let{queryString:n=!1,groupId:r}=e;if("string"==typeof n)return n;if(!1===n)return null;if(!0===n&&!r)throw Error('Docusaurus error: The <Tabs> component groupId prop is required if queryString=true, because this value is used as the search param name. You can also provide an explicit value such as queryString="my-search-param".');return r??null}({queryString:n,groupId:r});return[(0,c._X)(i),(0,t.useCallback)(e=>{if(!i)return;let n=new URLSearchParams(o.location.search);n.set(i,e),o.replace({...o.location,search:n.toString()})},[i,o])]}({queryString:r,groupId:o}),[g,y]=function(e){let{groupId:n}=e,r=n?`docusaurus.tab.${n}`:null,[o,i]=(0,p.Nk)(r);return[o,(0,t.useCallback)(e=>{r&&i.set(e)},[r,i])]}({groupId:o}),m=(()=>{let e=w??g;return h({value:e,tabValues:i})?e:null})();return(0,l.Z)(()=>{m&&x(m)},[m]),{selectedValue:a,selectValue:(0,t.useCallback)(e=>{if(!h({value:e,tabValues:i}))throw Error(`Can't select invalid tab value=${e}`);x(e),f(e),y(e)},[f,y,i]),tabValues:i}}(e);return(0,o.jsxs)("div",{className:(0,i.Z)("tabs-container","tabList__CuJ"),children:[(0,o.jsx)(w,{...n,...e}),(0,o.jsx)(f,{...n,...e})]})}function y(e){let n=(0,x.Z)();return(0,o.jsx)(g,{...e,children:d(e.children)},String(n))}},47927:function(e,n,r){r.d(n,{Z:function(){return u}});var o=r(85893);r(67294);var t=r(53367),i=r(89873),a=r(87262);let[s,l]=r(99074).version.split("."),c=[s,l].join("."),u=e=>{let{to:n,children:r}=e,s=(0,i.E)(),{siteConfig:l}=(0,a.default)();return l.presets[0][1].docs.disableVersioning||s.version===c?(0,o.jsx)(t.default,{to:`/api/${n}`,children:r}):(0,o.jsx)(t.default,{to:`/api/${"current"===s.version?"next":s.version}/${n}`,children:r})}},50065:function(e,n,r){r.d(n,{Z:function(){return s},a:function(){return a}});var o=r(67294);let t={},i=o.createContext(t);function a(e){let n=o.useContext(i);return o.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function s(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:a(e.components),o.createElement(i.Provider,{value:n},e.children)}},99074:function(e){e.exports=JSON.parse('{"name":"crawlee","version":"3.13.0","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","engines":{"node":">=16.0.0"},"bin":"./src/cli.ts","main":"./dist/index.js","module":"./dist/index.mjs","types":"./dist/index.d.ts","exports":{".":{"import":"./dist/index.mjs","require":"./dist/index.js","types":"./dist/index.d.ts"},"./package.json":"./package.json"},"keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"name":"Apify","email":"support@apify.com","url":"https://apify.com"},"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"license":"Apache-2.0","repository":{"type":"git","url":"git+https://github.com/apify/crawlee"},"bugs":{"url":"https://github.com/apify/crawlee/issues"},"homepage":"https://crawlee.dev","scripts":{"build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./dist/index.js ./dist/index.mjs","copy":"tsx ../../scripts/copy.ts"},"publishConfig":{"access":"public"},"dependencies":{"@crawlee/basic":"3.13.0","@crawlee/browser":"3.13.0","@crawlee/browser-pool":"3.13.0","@crawlee/cheerio":"3.13.0","@crawlee/cli":"3.13.0","@crawlee/core":"3.13.0","@crawlee/http":"3.13.0","@crawlee/jsdom":"3.13.0","@crawlee/linkedom":"3.13.0","@crawlee/playwright":"3.13.0","@crawlee/puppeteer":"3.13.0","@crawlee/utils":"3.13.0","import-local":"^3.1.0","tslib":"^2.4.0"},"peerDependencies":{"playwright":"*","puppeteer":"*"},"peerDependenciesMeta":{"playwright":{"optional":true},"puppeteer":{"optional":true}}}')}}]);