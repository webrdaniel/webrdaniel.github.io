"use strict";(self.webpackChunk=self.webpackChunk||[]).push([["59942"],{55429:function(e,t,r){r.r(t),r.d(t,{default:()=>m,frontMatter:()=>l,metadata:()=>n,assets:()=>p,toc:()=>d,contentTitle:()=>c});var n=JSON.parse('{"id":"examples/crawl-some-links","title":"Crawl some links on a website","description":"This CheerioCrawler example uses the globs property in the enqueueLinks() method to only add links to the RequestQueue queue if they match the specified pattern.","source":"@site/versioned_docs/version-3.4/examples/crawl_some_links.mdx","sourceDirName":"examples","slug":"/examples/crawl-some-links","permalink":"/docs/3.4/examples/crawl-some-links","draft":false,"unlisted":false,"editUrl":"https://github.com/apify/crawlee/edit/master/website/versioned_docs/version-3.4/examples/crawl_some_links.mdx","tags":[],"version":"3.4","lastUpdatedBy":"Jind\u0159ich B\xe4r","lastUpdatedAt":1686744725000,"frontMatter":{"id":"crawl-some-links","title":"Crawl some links on a website"},"sidebar":"docs","previous":{"title":"Crawl a sitemap","permalink":"/docs/3.4/examples/crawl-sitemap"},"next":{"title":"Using puppeteer-extra and playwright-extra","permalink":"/docs/3.4/examples/crawler-plugins/"}}'),s=r("85893"),i=r("50065"),a=r("96199"),o=r("47927");let l={id:"crawl-some-links",title:"Crawl some links on a website"},c=void 0,p={},d=[];function u(e){let t={code:"code",p:"p",...(0,i.a)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsxs)(t.p,{children:["This ",(0,s.jsx)(o.Z,{to:"cheerio-crawler/class/CheerioCrawler",children:(0,s.jsx)(t.code,{children:"CheerioCrawler"})})," example uses the ",(0,s.jsx)(o.Z,{to:"core/interface/EnqueueLinksOptions#globs",children:(0,s.jsx)(t.code,{children:"globs"})})," property in the ",(0,s.jsx)(o.Z,{to:"cheerio-crawler/interface/CheerioCrawlingContext#enqueueLinks",children:(0,s.jsx)(t.code,{children:"enqueueLinks()"})})," method to only add links to the ",(0,s.jsx)(o.Z,{to:"core/class/RequestQueue",children:(0,s.jsx)(t.code,{children:"RequestQueue"})})," queue if they match the specified pattern."]}),"\n",(0,s.jsx)(a.default,{className:"language-js",children:"import { CheerioCrawler } from 'crawlee';\n\n// Create a CheerioCrawler\nconst crawler = new CheerioCrawler({\n    // Limits the crawler to only 10 requests (do not use if you want to crawl all links)\n    maxRequestsPerCrawl: 10,\n    // Function called for each URL\n    async requestHandler({ request, enqueueLinks, log }) {\n        log.info(request.url);\n        // Add some links from page to the crawler's RequestQueue\n        await enqueueLinks({\n            globs: ['http?(s)://crawlee.dev/*/*'],\n        });\n    },\n});\n\n// Define the starting URL\nawait crawler.addRequests(['https://crawlee.dev']);\n\n// Run the crawler\nawait crawler.run();\n"})]})}function m(e={}){let{wrapper:t}={...(0,i.a)(),...e.components};return t?(0,s.jsx)(t,{...e,children:(0,s.jsx)(u,{...e})}):u(e)}},47927:function(e,t,r){r.d(t,{Z:function(){return p}});var n=r(85893);r(67294);var s=r(53367),i=r(89873),a=r(87262);let[o,l]=r(99074).version.split("."),c=[o,l].join("."),p=e=>{let{to:t,children:r}=e,o=(0,i.E)(),{siteConfig:l}=(0,a.default)();return l.presets[0][1].docs.disableVersioning||o.version===c?(0,n.jsx)(s.default,{to:`/api/${t}`,children:r}):(0,n.jsx)(s.default,{to:`/api/${"current"===o.version?"next":o.version}/${t}`,children:r})}},50065:function(e,t,r){r.d(t,{Z:function(){return o},a:function(){return a}});var n=r(67294);let s={},i=n.createContext(s);function a(e){let t=n.useContext(i);return n.useMemo(function(){return"function"==typeof e?e(t):{...t,...e}},[t,e])}function o(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:a(e.components),n.createElement(i.Provider,{value:t},e.children)}},99074:function(e){e.exports=JSON.parse('{"name":"crawlee","version":"3.13.0","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","engines":{"node":">=16.0.0"},"bin":"./src/cli.ts","main":"./dist/index.js","module":"./dist/index.mjs","types":"./dist/index.d.ts","exports":{".":{"import":"./dist/index.mjs","require":"./dist/index.js","types":"./dist/index.d.ts"},"./package.json":"./package.json"},"keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"name":"Apify","email":"support@apify.com","url":"https://apify.com"},"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"license":"Apache-2.0","repository":{"type":"git","url":"git+https://github.com/apify/crawlee"},"bugs":{"url":"https://github.com/apify/crawlee/issues"},"homepage":"https://crawlee.dev","scripts":{"build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./dist/index.js ./dist/index.mjs","copy":"tsx ../../scripts/copy.ts"},"publishConfig":{"access":"public"},"dependencies":{"@crawlee/basic":"3.13.0","@crawlee/browser":"3.13.0","@crawlee/browser-pool":"3.13.0","@crawlee/cheerio":"3.13.0","@crawlee/cli":"3.13.0","@crawlee/core":"3.13.0","@crawlee/http":"3.13.0","@crawlee/jsdom":"3.13.0","@crawlee/linkedom":"3.13.0","@crawlee/playwright":"3.13.0","@crawlee/puppeteer":"3.13.0","@crawlee/utils":"3.13.0","import-local":"^3.1.0","tslib":"^2.4.0"},"peerDependencies":{"playwright":"*","puppeteer":"*"},"peerDependenciesMeta":{"playwright":{"optional":true},"puppeteer":{"optional":true}}}')}}]);